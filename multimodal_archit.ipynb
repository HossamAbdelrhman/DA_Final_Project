{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching the list of root modules, please wait!\n",
      "(This will only be done once - type '%rehashx' to reset cache!)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D, Dense, Input, concatenate\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load listing data\n",
    "listing_data = pd.read_csv('./data/listings.csv')\n",
    "\n",
    "# copy the data frame to apply changes savely\n",
    "new_listing_df = listing_data.copy()\n",
    "\n",
    "# data pre-processing\n",
    "# drop identifiers & unrequired columns\n",
    "drop_cols_list = [\n",
    "    'scrape_id', 'name', 'description', 'neighborhood_overview',\n",
    "    'picture_url', 'host_id', 'host_url', 'host_name', 'host_location', 'host_about',\n",
    "    'host_response_time', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_verifications',\n",
    "    'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "    'bathrooms_text', 'amenities', 'license', 'last_scraped', 'source', 'host_since', 'calendar_updated',\n",
    "    'calendar_last_scraped', 'first_review', 'last_review'\n",
    "]\n",
    "new_listing_df.drop(drop_cols_list, axis=1, inplace=True)\n",
    "\n",
    "# drop records with null [price, host_response_rate, host_acceptance_rate] value\n",
    "new_listing_df = new_listing_df.dropna(axis=0, subset=['price', 'host_response_rate', 'host_acceptance_rate'])\n",
    "\n",
    "# encode T/F columns \n",
    "tf_columns = [\n",
    "    'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified',\n",
    "    'has_availability', 'instant_bookable',     \n",
    "]\n",
    "label_encoder = LabelEncoder().fit(new_listing_df['host_is_superhost'])\n",
    "for col in tf_columns:\n",
    "    new_listing_df[col] = label_encoder.transform(new_listing_df[col])\n",
    "\n",
    "# fill null numerical values with median\n",
    "cols_to_fill_miss_values = [\n",
    "    'reviews_per_month', 'review_scores_value', 'review_scores_location', 'review_scores_communication',\n",
    "    'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_accuracy', 'review_scores_rating', 'beds',\n",
    "    'bedrooms', 'bathrooms', \n",
    "]\n",
    "for col in cols_to_fill_miss_values:\n",
    "    new_listing_df[col] = new_listing_df[col].fillna(new_listing_df[col].median())\n",
    "\n",
    "# convert object values to numerical values\n",
    "obj_cols = ['host_response_rate', 'host_acceptance_rate']\n",
    "for col in obj_cols:\n",
    "    new_listing_df[col] = pd.to_numeric(new_listing_df[col].map(lambda val: val.replace('%', '')))\n",
    "new_listing_df['price'] = pd.to_numeric(new_listing_df['price'].map(lambda val: val.replace('$', '').replace(',', '')))\n",
    "\n",
    "\n",
    "# all two columns('images_names', 'images_No') with none values\n",
    "new_listing_df['images_names'] = [None for _ in range(len(new_listing_df))]\n",
    "new_listing_df['images_No'] = [ 0 for _ in range(len(new_listing_df))]\n",
    "\n",
    "new_listing_df.to_csv('./data/preprocessed_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19142 entries, 1 to 37763\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            19142 non-null  int64  \n",
      " 1   listing_url                                   19142 non-null  object \n",
      " 2   host_response_rate                            19142 non-null  int64  \n",
      " 3   host_acceptance_rate                          19142 non-null  int64  \n",
      " 4   host_is_superhost                             19142 non-null  int32  \n",
      " 5   host_listings_count                           19142 non-null  float64\n",
      " 6   host_total_listings_count                     19142 non-null  float64\n",
      " 7   host_has_profile_pic                          19142 non-null  int32  \n",
      " 8   host_identity_verified                        19142 non-null  int32  \n",
      " 9   latitude                                      19142 non-null  float64\n",
      " 10  longitude                                     19142 non-null  float64\n",
      " 11  accommodates                                  19142 non-null  int64  \n",
      " 12  bathrooms                                     19142 non-null  float64\n",
      " 13  bedrooms                                      19142 non-null  float64\n",
      " 14  beds                                          19142 non-null  float64\n",
      " 15  price                                         19142 non-null  float64\n",
      " 16  minimum_nights                                19142 non-null  int64  \n",
      " 17  maximum_nights                                19142 non-null  int64  \n",
      " 18  minimum_minimum_nights                        19142 non-null  float64\n",
      " 19  maximum_minimum_nights                        19142 non-null  float64\n",
      " 20  minimum_maximum_nights                        19142 non-null  float64\n",
      " 21  maximum_maximum_nights                        19142 non-null  float64\n",
      " 22  minimum_nights_avg_ntm                        19142 non-null  float64\n",
      " 23  maximum_nights_avg_ntm                        19142 non-null  float64\n",
      " 24  has_availability                              19142 non-null  int32  \n",
      " 25  availability_30                               19142 non-null  int64  \n",
      " 26  availability_60                               19142 non-null  int64  \n",
      " 27  availability_90                               19142 non-null  int64  \n",
      " 28  availability_365                              19142 non-null  int64  \n",
      " 29  number_of_reviews                             19142 non-null  int64  \n",
      " 30  number_of_reviews_ltm                         19142 non-null  int64  \n",
      " 31  number_of_reviews_l30d                        19142 non-null  int64  \n",
      " 32  review_scores_rating                          19142 non-null  float64\n",
      " 33  review_scores_accuracy                        19142 non-null  float64\n",
      " 34  review_scores_cleanliness                     19142 non-null  float64\n",
      " 35  review_scores_checkin                         19142 non-null  float64\n",
      " 36  review_scores_communication                   19142 non-null  float64\n",
      " 37  review_scores_location                        19142 non-null  float64\n",
      " 38  review_scores_value                           19142 non-null  float64\n",
      " 39  instant_bookable                              19142 non-null  int32  \n",
      " 40  calculated_host_listings_count                19142 non-null  int64  \n",
      " 41  calculated_host_listings_count_entire_homes   19142 non-null  int64  \n",
      " 42  calculated_host_listings_count_private_rooms  19142 non-null  int64  \n",
      " 43  calculated_host_listings_count_shared_rooms   19142 non-null  int64  \n",
      " 44  reviews_per_month                             19142 non-null  float64\n",
      " 45  images_names                                  0 non-null      object \n",
      " 46  images_No                                     19142 non-null  int64  \n",
      "dtypes: float64(22), int32(5), int64(18), object(2)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "new_listing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### We need to fill new columns (images_names, images_No) using script_of_image_scraping file first then follow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hossam Aboouf\\AppData\\Local\\Temp\\ipykernel_22788\\1733170965.py:3: DtypeWarning: Columns (46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('./data/preprocessed_listings.csv')\n"
     ]
    }
   ],
   "source": [
    "# read and prepare data\n",
    "img_size = (224, 224)\n",
    "data = pd.read_csv('./data/preprocessed_listings.csv')\n",
    "data = data.drop('Unnamed: 0', axis=1)[data['images_No'] == 5] # drop 'Unnamed: 0' column and use only recordes with images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1268 entries, 0 to 1323\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            1268 non-null   int64  \n",
      " 1   listing_url                                   1268 non-null   object \n",
      " 2   host_response_rate                            1268 non-null   int64  \n",
      " 3   host_acceptance_rate                          1268 non-null   int64  \n",
      " 4   host_is_superhost                             1268 non-null   int64  \n",
      " 5   host_listings_count                           1268 non-null   float64\n",
      " 6   host_total_listings_count                     1268 non-null   float64\n",
      " 7   host_has_profile_pic                          1268 non-null   int64  \n",
      " 8   host_identity_verified                        1268 non-null   int64  \n",
      " 9   latitude                                      1268 non-null   float64\n",
      " 10  longitude                                     1268 non-null   float64\n",
      " 11  accommodates                                  1268 non-null   int64  \n",
      " 12  bathrooms                                     1268 non-null   float64\n",
      " 13  bedrooms                                      1268 non-null   float64\n",
      " 14  beds                                          1268 non-null   float64\n",
      " 15  price                                         1268 non-null   float64\n",
      " 16  minimum_nights                                1268 non-null   int64  \n",
      " 17  maximum_nights                                1268 non-null   int64  \n",
      " 18  minimum_minimum_nights                        1268 non-null   float64\n",
      " 19  maximum_minimum_nights                        1268 non-null   float64\n",
      " 20  minimum_maximum_nights                        1268 non-null   float64\n",
      " 21  maximum_maximum_nights                        1268 non-null   float64\n",
      " 22  minimum_nights_avg_ntm                        1268 non-null   float64\n",
      " 23  maximum_nights_avg_ntm                        1268 non-null   float64\n",
      " 24  has_availability                              1268 non-null   int64  \n",
      " 25  availability_30                               1268 non-null   int64  \n",
      " 26  availability_60                               1268 non-null   int64  \n",
      " 27  availability_90                               1268 non-null   int64  \n",
      " 28  availability_365                              1268 non-null   int64  \n",
      " 29  number_of_reviews                             1268 non-null   int64  \n",
      " 30  number_of_reviews_ltm                         1268 non-null   int64  \n",
      " 31  number_of_reviews_l30d                        1268 non-null   int64  \n",
      " 32  review_scores_rating                          1268 non-null   float64\n",
      " 33  review_scores_accuracy                        1268 non-null   float64\n",
      " 34  review_scores_cleanliness                     1268 non-null   float64\n",
      " 35  review_scores_checkin                         1268 non-null   float64\n",
      " 36  review_scores_communication                   1268 non-null   float64\n",
      " 37  review_scores_location                        1268 non-null   float64\n",
      " 38  review_scores_value                           1268 non-null   float64\n",
      " 39  instant_bookable                              1268 non-null   int64  \n",
      " 40  calculated_host_listings_count                1268 non-null   int64  \n",
      " 41  calculated_host_listings_count_entire_homes   1268 non-null   int64  \n",
      " 42  calculated_host_listings_count_private_rooms  1268 non-null   int64  \n",
      " 43  calculated_host_listings_count_shared_rooms   1268 non-null   int64  \n",
      " 44  reviews_per_month                             1268 non-null   float64\n",
      " 45  images_names                                  1268 non-null   object \n",
      " 46  images_No                                     1268 non-null   int64  \n",
      "dtypes: float64(22), int64(23), object(2)\n",
      "memory usage: 475.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune CV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_and_prices(df):\n",
    "    paths = []\n",
    "    prices = []\n",
    "    for _, row in df.iterrows():\n",
    "        for name in row['images_names'].split(','):\n",
    "            paths.append(f'./images/{name}')\n",
    "            prices.append(row['price'])\n",
    "    return paths, prices\n",
    "\n",
    "def customise_data(data):\n",
    "    x_train, x_test, _, _ = train_test_split(data, [0 for _ in range(len(data))], test_size=.2, shuffle=True, random_state=303)\n",
    "    paths, prices = get_paths_and_prices(x_train)\n",
    "    dict_ = {\n",
    "        'imgs': paths,\n",
    "        'prices': prices\n",
    "    }\n",
    "    new_x_train = pd.DataFrame(dict_)\n",
    "\n",
    "    paths, prices = get_paths_and_prices(x_test)\n",
    "    dict_ = {\n",
    "        'imgs': paths,\n",
    "        'prices': prices\n",
    "    }\n",
    "    new_x_test = pd.DataFrame(dict_)\n",
    "\n",
    "    return new_x_train, new_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ avg_pool                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_94          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_cv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ avg_pool                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_94          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_cv (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m131,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,942,177</span> (83.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,942,177\u001b[0m (83.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,297</span> (528.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m135,297\u001b[0m (528.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,806,880</span> (83.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,806,880\u001b[0m (83.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5070 validated image filenames.\n",
      "Found 1270 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hossam Aboouf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1263: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hossam Aboouf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1273: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hossam Aboouf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 35786.0898 - mse: 35900.0859\n",
      "Epoch 1: val_loss improved from inf to 69936.89844, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 2s/step - loss: 35777.2188 - mse: 35893.2734 - val_loss: 69936.8984 - val_mse: 70367.5938\n",
      "Epoch 2/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988ms/step - loss: 36501.1719 - mse: 35608.3164\n",
      "Epoch 2: val_loss did not improve from 69936.89844\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 36460.0898 - mse: 35571.5195 - val_loss: 70186.3594 - val_mse: 69948.3203\n",
      "Epoch 3/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994ms/step - loss: 30606.0488 - mse: 30609.1777\n",
      "Epoch 3: val_loss did not improve from 69936.89844\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - loss: 30620.6914 - mse: 30624.0234 - val_loss: 70410.9062 - val_mse: 70797.6094\n",
      "Epoch 4/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981ms/step - loss: 31258.6113 - mse: 31306.0605\n",
      "Epoch 4: val_loss did not improve from 69936.89844\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - loss: 31259.0312 - mse: 31308.1934 - val_loss: 70571.3438 - val_mse: 70182.9453\n",
      "Epoch 5/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980ms/step - loss: 28601.2480 - mse: 28735.4258\n",
      "Epoch 5: val_loss improved from 69936.89844 to 69877.91406, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - loss: 28634.5215 - mse: 28769.3711 - val_loss: 69877.9141 - val_mse: 69619.4922\n",
      "Epoch 6/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981ms/step - loss: 25009.7441 - mse: 24744.6309\n",
      "Epoch 6: val_loss did not improve from 69877.91406\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - loss: 25087.2422 - mse: 24822.9238 - val_loss: 70224.5781 - val_mse: 70123.0547\n",
      "Epoch 7/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987ms/step - loss: 30896.3359 - mse: 30975.6562\n",
      "Epoch 7: val_loss did not improve from 69877.91406\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 30903.6895 - mse: 30985.2422 - val_loss: 70932.3047 - val_mse: 70686.2500\n",
      "Epoch 8/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980ms/step - loss: 35211.4766 - mse: 35280.8672\n",
      "Epoch 8: val_loss improved from 69877.91406 to 69480.62500, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - loss: 35163.2930 - mse: 35233.0781 - val_loss: 69480.6250 - val_mse: 69880.7188\n",
      "Epoch 9/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982ms/step - loss: 26140.5957 - mse: 27133.1387\n",
      "Epoch 9: val_loss did not improve from 69480.62500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - loss: 26201.5625 - mse: 27185.1680 - val_loss: 69661.0625 - val_mse: 69996.5391\n",
      "Epoch 10/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980ms/step - loss: 30025.0410 - mse: 30090.6172\n",
      "Epoch 10: val_loss did not improve from 69480.62500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - loss: 30033.9434 - mse: 30101.1836 - val_loss: 69631.4609 - val_mse: 69909.8438\n",
      "Epoch 11/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983ms/step - loss: 30621.1543 - mse: 30568.5625\n",
      "Epoch 11: val_loss did not improve from 69480.62500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - loss: 30632.0176 - mse: 30579.4629 - val_loss: 69510.7969 - val_mse: 69990.6953\n",
      "Epoch 12/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - loss: 30267.8828 - mse: 30629.6953\n",
      "Epoch 12: val_loss did not improve from 69480.62500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 30280.9062 - mse: 30639.6523 - val_loss: 69634.2812 - val_mse: 70098.6328\n",
      "Epoch 13/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982ms/step - loss: 33842.5000 - mse: 32706.1426\n",
      "Epoch 13: val_loss did not improve from 69480.62500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - loss: 33812.0391 - mse: 32685.2832 - val_loss: 69861.6484 - val_mse: 70322.8125\n",
      "Epoch 14/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982ms/step - loss: 31248.3379 - mse: 31266.0352\n",
      "Epoch 14: val_loss did not improve from 69480.62500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - loss: 31248.9785 - mse: 31268.9492 - val_loss: 70620.0625 - val_mse: 69849.3828\n",
      "Epoch 15/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 29699.2910 - mse: 29739.0234\n",
      "Epoch 15: val_loss did not improve from 69480.62500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - loss: 29720.1367 - mse: 29759.8750 - val_loss: 70869.1641 - val_mse: 70384.3828\n",
      "Epoch 16/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985ms/step - loss: 30909.4297 - mse: 30934.2930\n",
      "Epoch 16: val_loss did not improve from 69480.62500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 30926.6602 - mse: 30954.5137 - val_loss: 70118.5234 - val_mse: 69817.6172\n",
      "Epoch 17/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982ms/step - loss: 28114.5156 - mse: 28415.1602\n",
      "Epoch 17: val_loss did not improve from 69480.62500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - loss: 28152.0625 - mse: 28451.4609 - val_loss: 71067.6094 - val_mse: 70278.3984\n",
      "Epoch 18/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992ms/step - loss: 30250.2012 - mse: 29872.9824\n",
      "Epoch 18: val_loss improved from 69480.62500 to 69159.92188, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - loss: 30263.0000 - mse: 29889.8184 - val_loss: 69159.9219 - val_mse: 69614.9219\n",
      "Epoch 19/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978ms/step - loss: 28652.0996 - mse: 28929.0898\n",
      "Epoch 19: val_loss did not improve from 69159.92188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - loss: 28680.6113 - mse: 28956.1035 - val_loss: 72049.3359 - val_mse: 72493.3828\n",
      "Epoch 20/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981ms/step - loss: 28385.8535 - mse: 28603.0879\n",
      "Epoch 20: val_loss did not improve from 69159.92188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - loss: 28417.6562 - mse: 28635.4121 - val_loss: 69392.5547 - val_mse: 69735.3438\n",
      "Epoch 21/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 29659.6855 - mse: 29682.2305\n",
      "Epoch 21: val_loss did not improve from 69159.92188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - loss: 29681.0566 - mse: 29704.4160 - val_loss: 71572.0312 - val_mse: 71043.7578\n",
      "Epoch 22/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 30042.8418 - mse: 30083.6133\n",
      "Epoch 22: val_loss did not improve from 69159.92188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - loss: 30058.3516 - mse: 30101.6484 - val_loss: 69946.0859 - val_mse: 69556.0234\n",
      "Epoch 23/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 31175.4648 - mse: 31204.9297\n",
      "Epoch 23: val_loss did not improve from 69159.92188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - loss: 31172.8594 - mse: 31204.7988 - val_loss: 69909.2656 - val_mse: 70376.6016\n",
      "Epoch 24/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983ms/step - loss: 28085.3301 - mse: 28249.2930\n",
      "Epoch 24: val_loss did not improve from 69159.92188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 28121.8379 - mse: 28286.6895 - val_loss: 69989.4375 - val_mse: 69683.5469\n",
      "Epoch 25/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 32079.7070 - mse: 31530.3750\n",
      "Epoch 25: val_loss did not improve from 69159.92188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - loss: 32069.4238 - mse: 31523.3340 - val_loss: 70002.2500 - val_mse: 69676.4062\n",
      "Epoch 26/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - loss: 35071.7305 - mse: 35164.6992\n",
      "Epoch 26: val_loss improved from 69159.92188 to 69002.38281, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - loss: 35020.9531 - mse: 35115.6484 - val_loss: 69002.3828 - val_mse: 69449.1484\n",
      "Epoch 27/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983ms/step - loss: 30453.6055 - mse: 30688.9238\n",
      "Epoch 27: val_loss did not improve from 69002.38281\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 30461.1582 - mse: 30696.5996 - val_loss: 71660.6328 - val_mse: 71364.4375\n",
      "Epoch 28/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - loss: 29136.6074 - mse: 29170.4648\n",
      "Epoch 28: val_loss did not improve from 69002.38281\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 29167.6133 - mse: 29201.4492 - val_loss: 70508.9766 - val_mse: 70206.2188\n",
      "Epoch 29/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983ms/step - loss: 38258.0625 - mse: 38341.6445\n",
      "Epoch 29: val_loss did not improve from 69002.38281\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 38175.7773 - mse: 38261.6641 - val_loss: 69326.9375 - val_mse: 69807.9219\n",
      "Epoch 30/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - loss: 28826.8906 - mse: 28975.0312\n",
      "Epoch 30: val_loss did not improve from 69002.38281\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 28858.2285 - mse: 29005.9297 - val_loss: 69496.8906 - val_mse: 69954.9453\n",
      "Epoch 31/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987ms/step - loss: 23759.0723 - mse: 23963.5977\n",
      "Epoch 31: val_loss did not improve from 69002.38281\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 23847.1562 - mse: 24052.4414 - val_loss: 70878.6719 - val_mse: 69756.2422\n",
      "Epoch 32/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986ms/step - loss: 28685.4082 - mse: 28875.0312\n",
      "Epoch 32: val_loss did not improve from 69002.38281\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 28713.9902 - mse: 28903.8281 - val_loss: 70538.0781 - val_mse: 70904.4141\n",
      "Epoch 33/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990ms/step - loss: 29163.6387 - mse: 29034.0410\n",
      "Epoch 33: val_loss did not improve from 69002.38281\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 29192.4629 - mse: 29062.5000 - val_loss: 69677.6953 - val_mse: 70124.4375\n",
      "Epoch 34/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991ms/step - loss: 29378.7070 - mse: 29597.9688\n",
      "Epoch 34: val_loss did not improve from 69002.38281\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 29397.2188 - mse: 29616.7852 - val_loss: 69416.9219 - val_mse: 69859.2344\n",
      "Epoch 35/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988ms/step - loss: 28112.5566 - mse: 28524.3066\n",
      "Epoch 35: val_loss did not improve from 69002.38281\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 28153.7656 - mse: 28563.2949 - val_loss: 69194.2344 - val_mse: 69628.6484\n",
      "Epoch 36/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992ms/step - loss: 27895.4199 - mse: 28203.1992\n",
      "Epoch 36: val_loss did not improve from 69002.38281\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 27937.2051 - mse: 28243.5547 - val_loss: 70896.5781 - val_mse: 71338.3516\n",
      "Epoch 37/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 25748.9219 - mse: 25817.8926\n",
      "Epoch 37: val_loss improved from 69002.38281 to 68959.90625, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - loss: 25814.4551 - mse: 25885.1621 - val_loss: 68959.9062 - val_mse: 69417.5781\n",
      "Epoch 38/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - loss: 29683.7051 - mse: 30215.3359\n",
      "Epoch 38: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 29696.2988 - mse: 30224.1289 - val_loss: 69626.2969 - val_mse: 69330.9375\n",
      "Epoch 39/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986ms/step - loss: 30050.6777 - mse: 30080.1719\n",
      "Epoch 39: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 30064.7812 - mse: 30094.4551 - val_loss: 69847.1016 - val_mse: 69734.2500\n",
      "Epoch 40/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986ms/step - loss: 28814.2480 - mse: 28846.7773\n",
      "Epoch 40: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 28839.5215 - mse: 28873.0176 - val_loss: 69116.1953 - val_mse: 69598.6484\n",
      "Epoch 41/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - loss: 28417.9766 - mse: 28501.2285\n",
      "Epoch 41: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 28447.1484 - mse: 28532.3105 - val_loss: 69187.5547 - val_mse: 69633.0859\n",
      "Epoch 42/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986ms/step - loss: 32882.4922 - mse: 32872.6602\n",
      "Epoch 42: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 32869.1211 - mse: 32858.5352 - val_loss: 70798.4531 - val_mse: 69578.8984\n",
      "Epoch 43/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988ms/step - loss: 34885.0312 - mse: 34898.7812\n",
      "Epoch 43: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 34836.4414 - mse: 34852.6406 - val_loss: 70164.2109 - val_mse: 70637.7109\n",
      "Epoch 44/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 28308.0176 - mse: 28349.2383\n",
      "Epoch 44: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - loss: 28348.5801 - mse: 28392.3945 - val_loss: 69710.8984 - val_mse: 69626.3906\n",
      "Epoch 45/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988ms/step - loss: 31066.7500 - mse: 31095.2207\n",
      "Epoch 45: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 31065.2129 - mse: 31094.4473 - val_loss: 70282.8281 - val_mse: 70297.6172\n",
      "Epoch 46/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993ms/step - loss: 27567.2363 - mse: 27737.2480\n",
      "Epoch 46: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - loss: 27610.6543 - mse: 27781.6445 - val_loss: 69724.2734 - val_mse: 70175.8203\n",
      "Epoch 47/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993ms/step - loss: 28924.5059 - mse: 28945.5898\n",
      "Epoch 47: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 28957.4570 - mse: 28979.2070 - val_loss: 69051.6094 - val_mse: 69505.4453\n",
      "Epoch 48/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - loss: 31804.4727 - mse: 28288.0449\n",
      "Epoch 48: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 31837.4844 - mse: 28330.5625 - val_loss: 69180.3594 - val_mse: 69648.7031\n",
      "Epoch 49/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984ms/step - loss: 28016.4766 - mse: 28025.0137\n",
      "Epoch 49: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 28055.4082 - mse: 28066.6016 - val_loss: 71223.0156 - val_mse: 70149.2344\n",
      "Epoch 50/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991ms/step - loss: 28488.7754 - mse: 28679.1016\n",
      "Epoch 50: val_loss did not improve from 68959.90625\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 28523.2402 - mse: 28714.3730 - val_loss: 69125.3438 - val_mse: 69576.1328\n",
      "Epoch 51/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993ms/step - loss: 28994.0723 - mse: 29214.0059\n",
      "Epoch 51: val_loss improved from 68959.90625 to 68944.97656, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - loss: 29022.7090 - mse: 29242.7188 - val_loss: 68944.9766 - val_mse: 69326.9844\n",
      "Epoch 52/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987ms/step - loss: 30554.8633 - mse: 30671.0020\n",
      "Epoch 52: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 30558.3066 - mse: 30674.5859 - val_loss: 69360.4844 - val_mse: 69735.2812\n",
      "Epoch 53/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995ms/step - loss: 29909.8711 - mse: 29995.5332\n",
      "Epoch 53: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 29918.6895 - mse: 30006.3809 - val_loss: 73590.7344 - val_mse: 73187.9844\n",
      "Epoch 54/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996ms/step - loss: 33505.4531 - mse: 33326.6133\n",
      "Epoch 54: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - loss: 33482.9180 - mse: 33302.8281 - val_loss: 70459.1328 - val_mse: 69227.1094\n",
      "Epoch 55/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 29943.8027 - mse: 30128.3184\n",
      "Epoch 55: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - loss: 29960.9590 - mse: 30146.3379 - val_loss: 69055.2578 - val_mse: 69347.8516\n",
      "Epoch 56/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - loss: 29301.9863 - mse: 29329.9629\n",
      "Epoch 56: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 29323.2676 - mse: 29351.8242 - val_loss: 72306.3828 - val_mse: 72677.6797\n",
      "Epoch 57/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992ms/step - loss: 31603.3809 - mse: 31724.9570\n",
      "Epoch 57: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 31595.8867 - mse: 31716.9355 - val_loss: 70114.8906 - val_mse: 69697.5078\n",
      "Epoch 58/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999ms/step - loss: 30827.7617 - mse: 30829.3730\n",
      "Epoch 58: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - loss: 30830.7559 - mse: 30833.9414 - val_loss: 69992.9375 - val_mse: 69479.8984\n",
      "Epoch 59/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - loss: 27951.7324 - mse: 27494.6152\n",
      "Epoch 59: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 28028.4023 - mse: 27542.0000 - val_loss: 70512.2031 - val_mse: 69815.7266\n",
      "Epoch 60/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992ms/step - loss: 29816.7754 - mse: 29894.8789\n",
      "Epoch 60: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 29837.8027 - mse: 29917.0664 - val_loss: 69666.4609 - val_mse: 69323.8672\n",
      "Epoch 61/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - loss: 28215.2539 - mse: 28623.8027\n",
      "Epoch 61: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 28254.1621 - mse: 28660.6230 - val_loss: 69320.8906 - val_mse: 69049.2500\n",
      "Epoch 62/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998ms/step - loss: 35340.4531 - mse: 35337.8359\n",
      "Epoch 62: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - loss: 35283.7578 - mse: 35280.8711 - val_loss: 69016.3828 - val_mse: 69466.9141\n",
      "Epoch 63/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990ms/step - loss: 26593.9023 - mse: 26768.1211\n",
      "Epoch 63: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 26645.9219 - mse: 26820.8809 - val_loss: 69918.8281 - val_mse: 69606.3203\n",
      "Epoch 64/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994ms/step - loss: 27251.7383 - mse: 27402.7637\n",
      "Epoch 64: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 27298.6055 - mse: 27450.1719 - val_loss: 69880.4609 - val_mse: 69637.2969\n",
      "Epoch 65/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994ms/step - loss: 29060.3047 - mse: 27564.8945\n",
      "Epoch 65: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 29099.9180 - mse: 27609.7266 - val_loss: 69905.0625 - val_mse: 69503.0625\n",
      "Epoch 66/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991ms/step - loss: 39356.0391 - mse: 39361.8516\n",
      "Epoch 66: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 39257.1680 - mse: 39265.7578 - val_loss: 70381.7109 - val_mse: 70072.6172\n",
      "Epoch 67/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997ms/step - loss: 32622.2168 - mse: 32646.5781 \n",
      "Epoch 67: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - loss: 32603.6797 - mse: 32629.9883 - val_loss: 69542.4844 - val_mse: 69795.7422\n",
      "Epoch 68/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992ms/step - loss: 33154.1484 - mse: 33169.5977\n",
      "Epoch 68: val_loss did not improve from 68944.97656\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - loss: 33129.7070 - mse: 33145.1406 - val_loss: 70784.2344 - val_mse: 70486.7188\n",
      "Epoch 69/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984ms/step - loss: 31078.9473 - mse: 31140.8906\n",
      "Epoch 69: val_loss improved from 68944.97656 to 68782.37500, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - loss: 31077.9688 - mse: 31140.1816 - val_loss: 68782.3750 - val_mse: 69145.9766\n",
      "Epoch 70/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 34917.7227 - mse: 32295.2012\n",
      "Epoch 70: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - loss: 34880.4844 - mse: 32282.1367 - val_loss: 69075.8203 - val_mse: 69514.1094\n",
      "Epoch 71/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 28140.1836 - mse: 28182.4473\n",
      "Epoch 71: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - loss: 28173.3867 - mse: 28217.7012 - val_loss: 70120.1016 - val_mse: 70475.0547\n",
      "Epoch 72/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 30051.5039 - mse: 26645.1426\n",
      "Epoch 72: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 2s/step - loss: 30105.8359 - mse: 26699.7891 - val_loss: 69983.5938 - val_mse: 69625.4609\n",
      "Epoch 73/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 29069.6250 - mse: 29362.3281\n",
      "Epoch 73: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 2s/step - loss: 29092.8750 - mse: 29384.7109 - val_loss: 69865.9609 - val_mse: 70363.3672\n",
      "Epoch 74/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 29445.1875 - mse: 29178.0488\n",
      "Epoch 74: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - loss: 29473.3281 - mse: 29207.3984 - val_loss: 69280.9219 - val_mse: 69290.6484\n",
      "Epoch 75/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 32876.3086 - mse: 32758.1562\n",
      "Epoch 75: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - loss: 32874.1562 - mse: 32756.2910 - val_loss: 71757.3594 - val_mse: 70672.1641\n",
      "Epoch 76/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 29810.3594 - mse: 30004.5293\n",
      "Epoch 76: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - loss: 29834.4355 - mse: 30027.6211 - val_loss: 71544.1484 - val_mse: 70351.7578\n",
      "Epoch 77/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 28222.0312 - mse: 28220.3613\n",
      "Epoch 77: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - loss: 28260.4902 - mse: 28259.0840 - val_loss: 69833.8594 - val_mse: 69540.4688\n",
      "Epoch 78/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 30720.0547 - mse: 30894.5137\n",
      "Epoch 78: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - loss: 30723.1836 - mse: 30898.4941 - val_loss: 69100.0781 - val_mse: 69579.0234\n",
      "Epoch 79/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 34587.4336 - mse: 34689.7344\n",
      "Epoch 79: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - loss: 34542.5938 - mse: 34644.6289 - val_loss: 69612.6094 - val_mse: 69891.5781\n",
      "Epoch 80/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 33400.8086 - mse: 33481.5664\n",
      "Epoch 80: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 2s/step - loss: 33371.0352 - mse: 33452.6602 - val_loss: 71160.1875 - val_mse: 70903.3594\n",
      "Epoch 81/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 29243.4316 - mse: 29476.4883\n",
      "Epoch 81: val_loss did not improve from 68782.37500\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - loss: 29269.5762 - mse: 29501.9844 - val_loss: 72356.6641 - val_mse: 71591.4297\n",
      "Epoch 82/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 36606.6836 - mse: 33829.1367\n",
      "Epoch 82: val_loss improved from 68782.37500 to 68632.64062, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 2s/step - loss: 36572.7656 - mse: 33798.3750 - val_loss: 68632.6406 - val_mse: 69103.0391\n",
      "Epoch 83/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 30528.6211 - mse: 30584.9648\n",
      "Epoch 83: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - loss: 30535.8223 - mse: 30594.3379 - val_loss: 70516.1406 - val_mse: 70221.6406\n",
      "Epoch 84/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 32360.6191 - mse: 32351.1855\n",
      "Epoch 84: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - loss: 32344.8418 - mse: 32333.7031 - val_loss: 70496.9688 - val_mse: 70494.3125\n",
      "Epoch 85/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 28710.5938 - mse: 28718.1191\n",
      "Epoch 85: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 3s/step - loss: 28742.4746 - mse: 28750.3516 - val_loss: 70809.2500 - val_mse: 71152.6328\n",
      "Epoch 86/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 28515.0195 - mse: 28573.5996\n",
      "Epoch 86: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - loss: 28547.6973 - mse: 28607.5879 - val_loss: 71433.0469 - val_mse: 70283.7812\n",
      "Epoch 87/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 34019.4766 - mse: 34042.8750\n",
      "Epoch 87: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - loss: 33982.0742 - mse: 34006.6602 - val_loss: 69485.3984 - val_mse: 69955.6797\n",
      "Epoch 88/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 30486.5234 - mse: 30438.5293\n",
      "Epoch 88: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - loss: 30496.4824 - mse: 30446.2207 - val_loss: 69964.4453 - val_mse: 69690.6797\n",
      "Epoch 89/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 26766.9043 - mse: 27042.0703\n",
      "Epoch 89: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - loss: 26818.7090 - mse: 27092.5762 - val_loss: 71125.6641 - val_mse: 70662.7578\n",
      "Epoch 90/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 31139.3652 - mse: 31151.5117\n",
      "Epoch 90: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3s/step - loss: 31144.8672 - mse: 31157.0703 - val_loss: 70490.0547 - val_mse: 70936.5938\n",
      "Epoch 91/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 29130.5762 - mse: 29147.1777\n",
      "Epoch 91: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - loss: 29153.1660 - mse: 29171.5371 - val_loss: 68996.5391 - val_mse: 69365.8906\n",
      "Epoch 92/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 29750.8086 - mse: 29751.9082\n",
      "Epoch 92: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - loss: 29765.3457 - mse: 29766.3945 - val_loss: 71603.6719 - val_mse: 72048.2109\n",
      "Epoch 93/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 32070.6875 - mse: 32885.1992\n",
      "Epoch 93: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - loss: 32060.9297 - mse: 32867.9453 - val_loss: 70553.3359 - val_mse: 70970.0938\n",
      "Epoch 94/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 28996.0098 - mse: 28998.8184\n",
      "Epoch 94: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - loss: 29024.5742 - mse: 29030.1230 - val_loss: 69784.6406 - val_mse: 69495.8750\n",
      "Epoch 95/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 31342.1055 - mse: 31389.5332\n",
      "Epoch 95: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 3s/step - loss: 31339.1250 - mse: 31386.5762 - val_loss: 69194.2266 - val_mse: 69665.5547\n",
      "Epoch 96/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 37726.8008 - mse: 34296.9727\n",
      "Epoch 96: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - loss: 37689.0000 - mse: 34257.7812 - val_loss: 71624.7969 - val_mse: 71553.1562\n",
      "Epoch 97/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 26486.1055 - mse: 27006.0000\n",
      "Epoch 97: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - loss: 26541.2402 - mse: 27057.9297 - val_loss: 70674.7578 - val_mse: 69495.6797\n",
      "Epoch 98/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 31216.5879 - mse: 31645.3242\n",
      "Epoch 98: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - loss: 31215.8848 - mse: 31641.3652 - val_loss: 69740.4297 - val_mse: 69742.0625\n",
      "Epoch 99/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 29442.9707 - mse: 29459.1777\n",
      "Epoch 99: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3s/step - loss: 29461.3047 - mse: 29478.7051 - val_loss: 70165.3594 - val_mse: 70150.8828\n",
      "Epoch 100/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 33096.4023 - mse: 33937.9062\n",
      "Epoch 100: val_loss did not improve from 68632.64062\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 3s/step - loss: 33079.8086 - mse: 33913.4219 - val_loss: 69403.3906 - val_mse: 69129.9219\n",
      "Restoring model weights from the end of the best epoch: 82.\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = customise_data(data)\n",
    "\n",
    "# fine tune CV model (Inception v3)\n",
    "# Create the model\n",
    "img_input = Input(shape=(img_size[0], img_size[1], 3))\n",
    "Incep3_base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_tensor=img_input)\n",
    "\n",
    "# stop weight update\n",
    "for layer in Incep3_base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# update inseption model strcture by adding some layers to make it deal with our price prediction task\n",
    "Incep3_base_model = Incep3_base_model(img_input, training=False)\n",
    "Incep3_base_model = GlobalAveragePooling2D(name=\"avg_pool\")(Incep3_base_model)\n",
    "Incep3_base_model = BatchNormalization()(Incep3_base_model)\n",
    "Incep3_base_model = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense_hidden_cv')(Incep3_base_model)\n",
    "Incep3_base_model = Dense(1, activation='linear')(Incep3_base_model)\n",
    "Incep3_model = Model(inputs=img_input, outputs=Incep3_base_model)\n",
    "\n",
    "# initialize hyper-prameters\n",
    "lr = 0.1 \n",
    "verbose = 1\n",
    "epochs = 100\n",
    "batch_size = 64 \n",
    "        \n",
    "Incep3_model.compile(optimizer=Adam(learning_rate=lr, epsilon=1), metrics=['mse'], loss='mse')\n",
    "Incep3_model.summary()\n",
    "# plot_model(Incep3_model, show_shapes=True, to_file='./inceptionV3_model_image.png')\n",
    "stop = EarlyStopping(monitor=\"val_loss\", patience=30, restore_best_weights=True, mode='min', verbose=verbose)\n",
    "best = ModelCheckpoint(\n",
    "    filepath='./model/best_iv3_weights.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=verbose,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "train_img_generator = ImageDataGenerator(\n",
    "    brightness_range=(0.75, 1),\n",
    "    shear_range=0.1,\n",
    "    zoom_range=[0.50, 1],\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_img_generator = ImageDataGenerator(rescale=1.0)\n",
    "\n",
    "imgs_train = train_img_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col=\"imgs\",  \n",
    "        y_col=\"prices\",  \n",
    "        class_mode=\"raw\",  \n",
    "        color_mode='rgb',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size\n",
    "        )\n",
    "imgs_test = test_img_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col=\"imgs\",\n",
    "        y_col=\"prices\",\n",
    "        class_mode=\"raw\",\n",
    "        color_mode='rgb',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size\n",
    "        )\n",
    "\n",
    "hist = Incep3_model.fit(\n",
    "    imgs_train, \n",
    "    validation_data = imgs_test,\n",
    "    batch_size=batch_size,\n",
    "    verbose=verbose,\n",
    "    epochs=epochs,\n",
    "    callbacks=[stop, best]\n",
    ")\n",
    "\n",
    "Incep3_model.save('./model/last_iv3_model_simple.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune model for structure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read, prepare and split data\n",
    "data_std = data.drop(['id', 'listing_url', 'images_names', 'images_No'], axis=1)\n",
    "y_data_std = data_std['price']\n",
    "x_data_std = data_std.drop('price', axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data_std, y_data_std, test_size=.2, shuffle=True, random_state=303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_std (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_std (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,075</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_std (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │         \u001b[38;5;34m1,806\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_std (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,075\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,907</span> (11.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,907\u001b[0m (11.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,907</span> (11.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,907\u001b[0m (11.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# build std model (simple MLP algorithm)\n",
    "input_layer = Input(shape=(x_train.shape[1],), name='input_layer_std')\n",
    "base_model = Dense(x_train.shape[1], activation='relu', kernel_initializer='he_normal')(input_layer)\n",
    "base_model = Dense(25, activation='relu', name='dense_hidden_std')(base_model)\n",
    "output_layer = Dense(1, activation='linear')(base_model)\n",
    "model_std = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "print(model_std.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 592ms/step - loss: 253317.4688 - mean_squared_error: 253317.4688\n",
      "Epoch 1: val_loss improved from inf to 69836.10938, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 78115.6016 - mean_squared_error: 78115.6016 - val_loss: 69836.1094 - val_mean_squared_error: 69836.1094\n",
      "Epoch 2/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 16508.6855 - mean_squared_error: 16508.6855\n",
      "Epoch 2: val_loss did not improve from 69836.10938\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42303.2695 - mean_squared_error: 42303.2695 - val_loss: 70052.0391 - val_mean_squared_error: 70052.0391\n",
      "Epoch 3/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 15703.2363 - mean_squared_error: 15703.2363\n",
      "Epoch 3: val_loss did not improve from 69836.10938\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24029.2090 - mean_squared_error: 24029.2090 - val_loss: 72643.3984 - val_mean_squared_error: 72643.3984\n",
      "Epoch 4/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16232.6016 - mean_squared_error: 16232.6016\n",
      "Epoch 4: val_loss improved from 69836.10938 to 67173.33594, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33713.7812 - mean_squared_error: 33713.7812 - val_loss: 67173.3359 - val_mean_squared_error: 67173.3359\n",
      "Epoch 5/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 14358.1172 - mean_squared_error: 14358.1172\n",
      "Epoch 5: val_loss improved from 67173.33594 to 66834.40625, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25690.8242 - mean_squared_error: 25690.8242 - val_loss: 66834.4062 - val_mean_squared_error: 66834.4062\n",
      "Epoch 6/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 19797.9531 - mean_squared_error: 19797.9531\n",
      "Epoch 6: val_loss improved from 66834.40625 to 65856.52344, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37889.7734 - mean_squared_error: 37889.7734 - val_loss: 65856.5234 - val_mean_squared_error: 65856.5234\n",
      "Epoch 7/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7987.9180 - mean_squared_error: 7987.9180\n",
      "Epoch 7: val_loss improved from 65856.52344 to 64421.23828, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32914.9805 - mean_squared_error: 32914.9805 - val_loss: 64421.2383 - val_mean_squared_error: 64421.2383\n",
      "Epoch 8/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 19453.4395 - mean_squared_error: 19453.4395\n",
      "Epoch 8: val_loss improved from 64421.23828 to 63296.01562, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37323.8242 - mean_squared_error: 37323.8242 - val_loss: 63296.0156 - val_mean_squared_error: 63296.0156\n",
      "Epoch 9/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 8924.7891 - mean_squared_error: 8924.7891\n",
      "Epoch 9: val_loss improved from 63296.01562 to 62293.24609, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18800.1816 - mean_squared_error: 18800.1816 - val_loss: 62293.2461 - val_mean_squared_error: 62293.2461\n",
      "Epoch 10/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 24653.3770 - mean_squared_error: 24653.3770\n",
      "Epoch 10: val_loss did not improve from 62293.24609\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36571.4102 - mean_squared_error: 36571.4102 - val_loss: 62777.3438 - val_mean_squared_error: 62777.3438\n",
      "Epoch 11/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 11177.9121 - mean_squared_error: 11177.9121\n",
      "Epoch 11: val_loss improved from 62293.24609 to 61357.09766, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25533.5996 - mean_squared_error: 25533.5996 - val_loss: 61357.0977 - val_mean_squared_error: 61357.0977\n",
      "Epoch 12/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4382.7134 - mean_squared_error: 4382.7134\n",
      "Epoch 12: val_loss did not improve from 61357.09766\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18963.6992 - mean_squared_error: 18963.6992 - val_loss: 73358.0781 - val_mean_squared_error: 73358.0781\n",
      "Epoch 13/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 26700.6270 - mean_squared_error: 26700.6270\n",
      "Epoch 13: val_loss did not improve from 61357.09766\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36907.3477 - mean_squared_error: 36907.3477 - val_loss: 66516.5938 - val_mean_squared_error: 66516.5938\n",
      "Epoch 14/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9520.8740 - mean_squared_error: 9520.8740\n",
      "Epoch 14: val_loss did not improve from 61357.09766\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26629.5137 - mean_squared_error: 26629.5137 - val_loss: 61599.9062 - val_mean_squared_error: 61599.9062\n",
      "Epoch 15/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 12134.6504 - mean_squared_error: 12134.6504\n",
      "Epoch 15: val_loss did not improve from 61357.09766\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18593.7090 - mean_squared_error: 18593.7090 - val_loss: 61632.3633 - val_mean_squared_error: 61632.3633\n",
      "Epoch 16/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6663.2593 - mean_squared_error: 6663.2593\n",
      "Epoch 16: val_loss improved from 61357.09766 to 56436.66406, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22680.6641 - mean_squared_error: 22680.6641 - val_loss: 56436.6641 - val_mean_squared_error: 56436.6641\n",
      "Epoch 17/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6287.2856 - mean_squared_error: 6287.2856\n",
      "Epoch 17: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18676.6836 - mean_squared_error: 18676.6836 - val_loss: 58877.1953 - val_mean_squared_error: 58877.1953\n",
      "Epoch 18/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 13027.2461 - mean_squared_error: 13027.2461\n",
      "Epoch 18: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27392.2188 - mean_squared_error: 27392.2188 - val_loss: 69667.9844 - val_mean_squared_error: 69667.9844\n",
      "Epoch 19/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 20439.1836 - mean_squared_error: 20439.1836\n",
      "Epoch 19: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36068.5781 - mean_squared_error: 36068.5781 - val_loss: 62931.9297 - val_mean_squared_error: 62931.9297\n",
      "Epoch 20/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 14677.9375 - mean_squared_error: 14677.9375\n",
      "Epoch 20: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21920.0508 - mean_squared_error: 21920.0508 - val_loss: 61902.7227 - val_mean_squared_error: 61902.7227\n",
      "Epoch 21/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17014.4883 - mean_squared_error: 17014.4883\n",
      "Epoch 21: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23942.9297 - mean_squared_error: 23942.9297 - val_loss: 63689.9453 - val_mean_squared_error: 63689.9453\n",
      "Epoch 22/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 13593.2871 - mean_squared_error: 13593.2871\n",
      "Epoch 22: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22815.7637 - mean_squared_error: 22815.7637 - val_loss: 62767.3594 - val_mean_squared_error: 62767.3594\n",
      "Epoch 23/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7027.8877 - mean_squared_error: 7027.8877\n",
      "Epoch 23: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19484.7188 - mean_squared_error: 19484.7188 - val_loss: 66075.1953 - val_mean_squared_error: 66075.1953\n",
      "Epoch 24/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10149.0273 - mean_squared_error: 10149.0273\n",
      "Epoch 24: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20749.1602 - mean_squared_error: 20749.1602 - val_loss: 61749.9688 - val_mean_squared_error: 61749.9688\n",
      "Epoch 25/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12478.8887 - mean_squared_error: 12478.8887\n",
      "Epoch 25: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18351.5625 - mean_squared_error: 18351.5625 - val_loss: 57118.0703 - val_mean_squared_error: 57118.0703\n",
      "Epoch 26/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 26394.0078 - mean_squared_error: 26394.0078\n",
      "Epoch 26: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20542.9844 - mean_squared_error: 20542.9844 - val_loss: 72587.0938 - val_mean_squared_error: 72587.0938\n",
      "Epoch 27/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 19627.9375 - mean_squared_error: 19627.9375\n",
      "Epoch 27: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21746.9473 - mean_squared_error: 21746.9473 - val_loss: 78111.6719 - val_mean_squared_error: 78111.6719\n",
      "Epoch 28/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 14841.1777 - mean_squared_error: 14841.1777\n",
      "Epoch 28: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21410.3438 - mean_squared_error: 21410.3438 - val_loss: 57547.4414 - val_mean_squared_error: 57547.4414\n",
      "Epoch 29/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9717.6865 - mean_squared_error: 9717.6865\n",
      "Epoch 29: val_loss did not improve from 56436.66406\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17025.7441 - mean_squared_error: 17025.7441 - val_loss: 65882.4688 - val_mean_squared_error: 65882.4688\n",
      "Epoch 30/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 34360.6758 - mean_squared_error: 34360.6758\n",
      "Epoch 30: val_loss improved from 56436.66406 to 56376.99219, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20414.7773 - mean_squared_error: 20414.7773 - val_loss: 56376.9922 - val_mean_squared_error: 56376.9922\n",
      "Epoch 31/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4689.7793 - mean_squared_error: 4689.7793\n",
      "Epoch 31: val_loss did not improve from 56376.99219\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21622.4473 - mean_squared_error: 21622.4473 - val_loss: 62938.3711 - val_mean_squared_error: 62938.3711\n",
      "Epoch 32/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 12464.0361 - mean_squared_error: 12464.0361\n",
      "Epoch 32: val_loss improved from 56376.99219 to 53931.97656, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21594.8164 - mean_squared_error: 21594.8164 - val_loss: 53931.9766 - val_mean_squared_error: 53931.9766\n",
      "Epoch 33/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 21701.3945 - mean_squared_error: 21701.3945\n",
      "Epoch 33: val_loss improved from 53931.97656 to 50533.39844, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18440.8164 - mean_squared_error: 18440.8164 - val_loss: 50533.3984 - val_mean_squared_error: 50533.3984\n",
      "Epoch 34/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17198.6914 - mean_squared_error: 17198.6914\n",
      "Epoch 34: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16604.8340 - mean_squared_error: 16604.8340 - val_loss: 54730.6289 - val_mean_squared_error: 54730.6289\n",
      "Epoch 35/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 16117.3301 - mean_squared_error: 16117.3301\n",
      "Epoch 35: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22026.8887 - mean_squared_error: 22026.8887 - val_loss: 61885.5703 - val_mean_squared_error: 61885.5703\n",
      "Epoch 36/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7782.5562 - mean_squared_error: 7782.5562\n",
      "Epoch 36: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12834.7080 - mean_squared_error: 12834.7080 - val_loss: 66625.3359 - val_mean_squared_error: 66625.3359\n",
      "Epoch 37/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16795.2383 - mean_squared_error: 16795.2383\n",
      "Epoch 37: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20148.2070 - mean_squared_error: 20148.2070 - val_loss: 64353.8281 - val_mean_squared_error: 64353.8281\n",
      "Epoch 38/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 23298.0371 - mean_squared_error: 23298.0371\n",
      "Epoch 38: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28023.8281 - mean_squared_error: 28023.8281 - val_loss: 58599.2266 - val_mean_squared_error: 58599.2266\n",
      "Epoch 39/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 24333.7109 - mean_squared_error: 24333.7109\n",
      "Epoch 39: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13651.1172 - mean_squared_error: 13651.1172 - val_loss: 53246.0117 - val_mean_squared_error: 53246.0117\n",
      "Epoch 40/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 138216.3906 - mean_squared_error: 138216.3906\n",
      "Epoch 40: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30653.9785 - mean_squared_error: 30653.9785 - val_loss: 54140.3750 - val_mean_squared_error: 54140.3750\n",
      "Epoch 41/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9590.1250 - mean_squared_error: 9590.1250\n",
      "Epoch 41: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11599.9678 - mean_squared_error: 11599.9678 - val_loss: 58013.0312 - val_mean_squared_error: 58013.0312\n",
      "Epoch 42/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 16539.5273 - mean_squared_error: 16539.5273\n",
      "Epoch 42: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27263.7305 - mean_squared_error: 27263.7305 - val_loss: 54914.5039 - val_mean_squared_error: 54914.5039\n",
      "Epoch 43/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 23317.8867 - mean_squared_error: 23317.8867\n",
      "Epoch 43: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15910.3496 - mean_squared_error: 15910.3496 - val_loss: 65386.2461 - val_mean_squared_error: 65386.2461\n",
      "Epoch 44/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7732.1992 - mean_squared_error: 7732.1992\n",
      "Epoch 44: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19151.5078 - mean_squared_error: 19151.5078 - val_loss: 54291.3125 - val_mean_squared_error: 54291.3125\n",
      "Epoch 45/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4144.1719 - mean_squared_error: 4144.1719\n",
      "Epoch 45: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14562.0264 - mean_squared_error: 14562.0264 - val_loss: 57736.0703 - val_mean_squared_error: 57736.0703\n",
      "Epoch 46/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 36799.3359 - mean_squared_error: 36799.3359\n",
      "Epoch 46: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16710.1797 - mean_squared_error: 16710.1797 - val_loss: 56043.0781 - val_mean_squared_error: 56043.0781\n",
      "Epoch 47/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 15436.9238 - mean_squared_error: 15436.9238\n",
      "Epoch 47: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14316.6338 - mean_squared_error: 14316.6338 - val_loss: 56740.9609 - val_mean_squared_error: 56740.9609\n",
      "Epoch 48/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 25470.6582 - mean_squared_error: 25470.6582\n",
      "Epoch 48: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21835.9277 - mean_squared_error: 21835.9277 - val_loss: 57709.8789 - val_mean_squared_error: 57709.8789\n",
      "Epoch 49/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 14074.6426 - mean_squared_error: 14074.6426\n",
      "Epoch 49: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14168.8555 - mean_squared_error: 14168.8555 - val_loss: 54291.5586 - val_mean_squared_error: 54291.5586\n",
      "Epoch 50/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 11858.6504 - mean_squared_error: 11858.6504\n",
      "Epoch 50: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26545.8945 - mean_squared_error: 26545.8945 - val_loss: 55615.0000 - val_mean_squared_error: 55615.0000\n",
      "Epoch 51/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8645.9355 - mean_squared_error: 8645.9355\n",
      "Epoch 51: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18766.6680 - mean_squared_error: 18766.6680 - val_loss: 56751.5898 - val_mean_squared_error: 56751.5898\n",
      "Epoch 52/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10505.2559 - mean_squared_error: 10505.2559\n",
      "Epoch 52: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19596.4062 - mean_squared_error: 19596.4062 - val_loss: 55531.1992 - val_mean_squared_error: 55531.1992\n",
      "Epoch 53/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 18280.7949 - mean_squared_error: 18280.7949\n",
      "Epoch 53: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13670.7236 - mean_squared_error: 13670.7236 - val_loss: 53511.1797 - val_mean_squared_error: 53511.1797\n",
      "Epoch 54/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5839.1553 - mean_squared_error: 5839.1553\n",
      "Epoch 54: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18048.6504 - mean_squared_error: 18048.6504 - val_loss: 55920.8633 - val_mean_squared_error: 55920.8633\n",
      "Epoch 55/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9741.9443 - mean_squared_error: 9741.9443\n",
      "Epoch 55: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20132.8145 - mean_squared_error: 20132.8145 - val_loss: 52749.5469 - val_mean_squared_error: 52749.5469\n",
      "Epoch 56/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8626.7500 - mean_squared_error: 8626.7500\n",
      "Epoch 56: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14441.9111 - mean_squared_error: 14441.9111 - val_loss: 60497.6562 - val_mean_squared_error: 60497.6562\n",
      "Epoch 57/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6875.8042 - mean_squared_error: 6875.8042\n",
      "Epoch 57: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16609.3965 - mean_squared_error: 16609.3965 - val_loss: 53839.7188 - val_mean_squared_error: 53839.7188\n",
      "Epoch 58/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 14661.0459 - mean_squared_error: 14661.0459\n",
      "Epoch 58: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15254.3379 - mean_squared_error: 15254.3379 - val_loss: 52757.4062 - val_mean_squared_error: 52757.4062\n",
      "Epoch 59/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10286.9766 - mean_squared_error: 10286.9766\n",
      "Epoch 59: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12188.9814 - mean_squared_error: 12188.9814 - val_loss: 52395.1016 - val_mean_squared_error: 52395.1016\n",
      "Epoch 60/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 17584.7129 - mean_squared_error: 17584.7129\n",
      "Epoch 60: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17000.4746 - mean_squared_error: 17000.4746 - val_loss: 50861.8438 - val_mean_squared_error: 50861.8438\n",
      "Epoch 61/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 10308.5586 - mean_squared_error: 10308.5586\n",
      "Epoch 61: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11664.0664 - mean_squared_error: 11664.0664 - val_loss: 52522.8711 - val_mean_squared_error: 52522.8711\n",
      "Epoch 62/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 10348.2637 - mean_squared_error: 10348.2637\n",
      "Epoch 62: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9793.0254 - mean_squared_error: 9793.0254 - val_loss: 53021.6797 - val_mean_squared_error: 53021.6797\n",
      "Epoch 63/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 16583.8105 - mean_squared_error: 16583.8105\n",
      "Epoch 63: val_loss did not improve from 50533.39844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13334.2881 - mean_squared_error: 13334.2881 - val_loss: 51575.0273 - val_mean_squared_error: 51575.0273\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n"
     ]
    }
   ],
   "source": [
    "# compile and train the model\n",
    "epochs = 400\n",
    "lr = ExponentialDecay(0.01, decay_steps=100000, decay_rate=0.96, staircase=True)\n",
    "stop = EarlyStopping(monitor=\"val_loss\", patience=30, restore_best_weights=True, mode='min', verbose=verbose)\n",
    "best = ModelCheckpoint(\n",
    "    filepath='./model/best_std_weights.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=verbose,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "model_std.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[MeanSquaredError()],\n",
    "    optimizer=Adam(learning_rate=lr, epsilon=1)\n",
    ")\n",
    "# plot_model(model_std, show_shapes=True, to_file='./model_std.png')\n",
    "\n",
    "hist_std = model_std.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[stop, best],\n",
    "    validation_data=([x_test, y_test])\n",
    ")\n",
    "\n",
    "model_std.save('./model/last_std_weights.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune multi-modal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_XY_data(df:pd.DataFrame):\n",
    "    df_copy = df.copy()\n",
    "    x_imgs = []\n",
    "    y = []\n",
    "    for i, row in df.iterrows():\n",
    "        img_names = row['images_names'].split(',')\n",
    "        for img_name in img_names:\n",
    "            img_path = f'./images/{img_name}'\n",
    "            # print(img_path)\n",
    "            img = load_img(img_path, target_size=img_size)\n",
    "            img = img_to_array(img)\n",
    "            # img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "            x_imgs.append(img)\n",
    "            y.append(row['price'])\n",
    "    Y = pd.DataFrame({'price': y})\n",
    "    x_std = df_copy.drop(['id', 'listing_url', 'images_names', 'images_No', 'price'], axis=1)\n",
    "    x_std = pd.DataFrame(np.repeat(x_std.values, 5, axis=0), columns=x_std.columns)\n",
    "    \n",
    "    return np.array(x_imgs), x_std, Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train imgs len: 5070\n",
      "X_train std shape: (5070, 42)\n",
      "Y_train std shape: (5070, 1)\n",
      "X_test imgs len: 1270\n",
      "X_test std shape: (1270, 42)\n",
      "Y_test std shape: (1270, 1)\n"
     ]
    }
   ],
   "source": [
    "# python code to create the final architecture\n",
    "\n",
    "train_df, test_df, _, _ = train_test_split(data, [0 for _ in range(len(data))], test_size=.2, shuffle=True, random_state=303)\n",
    "# load data (training)\n",
    "x_train_imgs, x_train_std, y_train = split_XY_data(train_df)\n",
    "print(f'X_train imgs len: {len(x_train_imgs)}')\n",
    "print(f'X_train std shape: {x_train_std.shape}')\n",
    "print(f'Y_train std shape: {y_train.shape}')\n",
    "\n",
    "# load data (testing)\n",
    "x_test_imgs, x_test_std, y_test = split_XY_data(test_df)\n",
    "print(f'X_test imgs len: {len(x_test_imgs)}')\n",
    "print(f'X_test std shape: {x_test_std.shape}')\n",
    "print(f'Y_test std shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build multimodal NN\n",
    "\n",
    "# load fine tuned models\n",
    "# 1) load computer vision model\n",
    "cv_tuned_model_path = './model/best_iv3_weights.keras'\n",
    "cv_tuned_model = keras.models.load_model(cv_tuned_model_path, compile=False)\n",
    "# 2) load structured model\n",
    "std_tuned_model_path = './model/best_std_weights.keras'\n",
    "std_tuned_model = keras.models.load_model(std_tuned_model_path, compile=False)\n",
    "\n",
    "# remove last layer from each model\n",
    "# just to simply identify the layers after concatenation we will add postfix (_cv, _std) for layers\n",
    "# _cv => to layers of computer vision model layers\n",
    "# _std => to layers of structure NN model layers\n",
    "cv_tuned_model_layer = Model(inputs=cv_tuned_model.input, outputs=cv_tuned_model.layers[-2].output)\n",
    "for layer in cv_tuned_model_layer.layers:\n",
    "    layer._name = f'{layer.name}_cv'\n",
    "std_tuned_model_layer = Model(inputs=std_tuned_model.input, outputs=std_tuned_model.layers[-2].output)\n",
    "for layer in std_tuned_model_layer.layers:\n",
    "    layer._name = f'{layer.name}_std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ inception_v3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ avg_pool            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inception_v3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_std     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ avg_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │ input_layer_std[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden_cv     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden_std    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,075</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_hidden_cv[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_hidden_std… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden_final  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,500</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dense_hidden_fin… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ inception_v3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m,      │ \u001b[38;5;34m21,802,784\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ avg_pool            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ inception_v3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_std     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │      \u001b[38;5;34m8,192\u001b[0m │ avg_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)        │      \u001b[38;5;34m1,806\u001b[0m │ input_layer_std[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden_cv     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │    \u001b[38;5;34m131,136\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden_std    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)        │      \u001b[38;5;34m1,075\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_hidden_cv[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_hidden_std… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden_final  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │      \u001b[38;5;34m4,500\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dense_hidden_fin… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,949,544</span> (83.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,949,544\u001b[0m (83.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,911,016</span> (83.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,911,016\u001b[0m (83.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,528</span> (150.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m38,528\u001b[0m (150.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# concate models and add 2 final layer\n",
    "multimodal_structure = concatenate([\n",
    "    cv_tuned_model_layer.output,\n",
    "    std_tuned_model_layer.output\n",
    "])\n",
    "multimodal_structure = Dense(50, activation='relu', name='dense_hidden_final')(multimodal_structure)\n",
    "multimodal_structure = Dense(1, activation='linear')(multimodal_structure)\n",
    "\n",
    "# build model\n",
    "multimodal_model = keras.Model(inputs=[\n",
    "    cv_tuned_model_layer.input[0], \n",
    "    std_tuned_model_layer.input[0]],\n",
    "    outputs=[multimodal_structure]\n",
    ")\n",
    "\n",
    "# model compilation\n",
    "lr = 0.01\n",
    "multimodal_model.compile(\n",
    "    optimizer=Adam(learning_rate=lr, epsilon=1),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[ MeanSquaredError()]\n",
    ")\n",
    "\n",
    "print(multimodal_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# plot model\n",
    "plot_model(\n",
    "    multimodal_model,\n",
    "    dpi=350,\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    to_file=\"multimodal_model.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 23948.4707 - mean_squared_error: 23948.4707\n",
      "Epoch 1: val_loss improved from inf to 53250.72656, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 10s/step - loss: 23797.1230 - mean_squared_error: 23797.1230 - val_loss: 53250.7266 - val_mean_squared_error: 53250.7266\n",
      "Epoch 2/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 18638.5801 - mean_squared_error: 18638.5801\n",
      "Epoch 2: val_loss improved from 53250.72656 to 51812.46094, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 10s/step - loss: 18539.0664 - mean_squared_error: 18539.0664 - val_loss: 51812.4609 - val_mean_squared_error: 51812.4609\n",
      "Epoch 3/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 16242.9043 - mean_squared_error: 16242.9043\n",
      "Epoch 3: val_loss improved from 51812.46094 to 51208.70703, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 10s/step - loss: 16216.2070 - mean_squared_error: 16216.2070 - val_loss: 51208.7070 - val_mean_squared_error: 51208.7070\n",
      "Epoch 4/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 13555.6865 - mean_squared_error: 13555.6865\n",
      "Epoch 4: val_loss did not improve from 51208.70703\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 10s/step - loss: 13699.2783 - mean_squared_error: 13699.2783 - val_loss: 52324.8984 - val_mean_squared_error: 52324.8984\n",
      "Epoch 5/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 14964.3750 - mean_squared_error: 14964.3750\n",
      "Epoch 5: val_loss improved from 51208.70703 to 49230.90625, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 10s/step - loss: 14981.2686 - mean_squared_error: 14981.2686 - val_loss: 49230.9062 - val_mean_squared_error: 49230.9062\n",
      "Epoch 6/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 18723.4414 - mean_squared_error: 18723.4414\n",
      "Epoch 6: val_loss did not improve from 49230.90625\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 10s/step - loss: 18567.6191 - mean_squared_error: 18567.6191 - val_loss: 52125.8945 - val_mean_squared_error: 52125.8945\n",
      "Epoch 7/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 22760.8652 - mean_squared_error: 22760.8652 \n",
      "Epoch 7: val_loss did not improve from 49230.90625\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 12s/step - loss: 22403.2500 - mean_squared_error: 22403.2500 - val_loss: 51661.5078 - val_mean_squared_error: 51661.5078\n",
      "Epoch 8/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 15425.4502 - mean_squared_error: 15425.4502 \n",
      "Epoch 8: val_loss did not improve from 49230.90625\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 11s/step - loss: 15379.1006 - mean_squared_error: 15379.1006 - val_loss: 51056.2305 - val_mean_squared_error: 51056.2305\n",
      "Epoch 9/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13852.6318 - mean_squared_error: 13852.6318 \n",
      "Epoch 9: val_loss did not improve from 49230.90625\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 11s/step - loss: 13863.6855 - mean_squared_error: 13863.6855 - val_loss: 53520.9453 - val_mean_squared_error: 53520.9453\n",
      "Epoch 10/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 15826.2578 - mean_squared_error: 15826.2578 \n",
      "Epoch 10: val_loss improved from 49230.90625 to 48647.55859, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 12s/step - loss: 15753.9072 - mean_squared_error: 15753.9072 - val_loss: 48647.5586 - val_mean_squared_error: 48647.5586\n",
      "Epoch 11/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 15080.9414 - mean_squared_error: 15080.9414 \n",
      "Epoch 11: val_loss improved from 48647.55859 to 46105.22266, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 12s/step - loss: 15043.5654 - mean_squared_error: 15043.5654 - val_loss: 46105.2227 - val_mean_squared_error: 46105.2227\n",
      "Epoch 12/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13870.2471 - mean_squared_error: 13870.2471 \n",
      "Epoch 12: val_loss did not improve from 46105.22266\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 11s/step - loss: 13944.3672 - mean_squared_error: 13944.3672 - val_loss: 55225.7617 - val_mean_squared_error: 55225.7617\n",
      "Epoch 13/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13670.8340 - mean_squared_error: 13670.8340 \n",
      "Epoch 13: val_loss improved from 46105.22266 to 45978.28906, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 12s/step - loss: 13731.9346 - mean_squared_error: 13731.9346 - val_loss: 45978.2891 - val_mean_squared_error: 45978.2891\n",
      "Epoch 14/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 9940.1104 - mean_squared_error: 9940.1104 \n",
      "Epoch 14: val_loss improved from 45978.28906 to 39043.75391, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 12s/step - loss: 10113.1553 - mean_squared_error: 10113.1553 - val_loss: 39043.7539 - val_mean_squared_error: 39043.7539\n",
      "Epoch 15/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 14925.5381 - mean_squared_error: 14925.5381 \n",
      "Epoch 15: val_loss did not improve from 39043.75391\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 12s/step - loss: 14810.1553 - mean_squared_error: 14810.1553 - val_loss: 40831.7305 - val_mean_squared_error: 40831.7305\n",
      "Epoch 16/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 10930.5898 - mean_squared_error: 10930.5898 \n",
      "Epoch 16: val_loss did not improve from 39043.75391\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 12s/step - loss: 10979.8418 - mean_squared_error: 10979.8418 - val_loss: 40880.0039 - val_mean_squared_error: 40880.0039\n",
      "Epoch 17/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 11489.4756 - mean_squared_error: 11489.4756 \n",
      "Epoch 17: val_loss did not improve from 39043.75391\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 12s/step - loss: 11539.9180 - mean_squared_error: 11539.9180 - val_loss: 42494.9688 - val_mean_squared_error: 42494.9688\n",
      "Epoch 18/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 12568.1318 - mean_squared_error: 12568.1318 \n",
      "Epoch 18: val_loss improved from 39043.75391 to 37979.70312, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 12s/step - loss: 12606.3184 - mean_squared_error: 12606.3184 - val_loss: 37979.7031 - val_mean_squared_error: 37979.7031\n",
      "Epoch 19/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13133.1104 - mean_squared_error: 13133.1104 \n",
      "Epoch 19: val_loss did not improve from 37979.70312\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 11s/step - loss: 13178.4756 - mean_squared_error: 13178.4756 - val_loss: 50378.0859 - val_mean_squared_error: 50378.0859\n",
      "Epoch 20/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 15950.7217 - mean_squared_error: 15950.7217 \n",
      "Epoch 20: val_loss did not improve from 37979.70312\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 12s/step - loss: 15812.3232 - mean_squared_error: 15812.3232 - val_loss: 42050.2148 - val_mean_squared_error: 42050.2148\n",
      "Epoch 21/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 15123.7920 - mean_squared_error: 15123.7920 \n",
      "Epoch 21: val_loss did not improve from 37979.70312\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 12s/step - loss: 15036.8682 - mean_squared_error: 15036.8682 - val_loss: 51297.2266 - val_mean_squared_error: 51297.2266\n",
      "Epoch 22/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 12803.6797 - mean_squared_error: 12803.6797 \n",
      "Epoch 22: val_loss did not improve from 37979.70312\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 12s/step - loss: 12874.3896 - mean_squared_error: 12874.3896 - val_loss: 61455.1172 - val_mean_squared_error: 61455.1172\n",
      "Epoch 23/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 16533.3398 - mean_squared_error: 16533.3398 \n",
      "Epoch 23: val_loss did not improve from 37979.70312\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 12s/step - loss: 16430.7988 - mean_squared_error: 16430.7988 - val_loss: 39917.5078 - val_mean_squared_error: 39917.5078\n",
      "Epoch 24/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 14949.9717 - mean_squared_error: 14949.9717 \n",
      "Epoch 24: val_loss did not improve from 37979.70312\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 12s/step - loss: 14809.4375 - mean_squared_error: 14809.4375 - val_loss: 40500.2891 - val_mean_squared_error: 40500.2891\n",
      "Epoch 25/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 11898.1338 - mean_squared_error: 11898.1338 \n",
      "Epoch 25: val_loss improved from 37979.70312 to 30687.70312, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 12s/step - loss: 11878.1758 - mean_squared_error: 11878.1758 - val_loss: 30687.7031 - val_mean_squared_error: 30687.7031\n",
      "Epoch 26/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 10772.7363 - mean_squared_error: 10772.7363 \n",
      "Epoch 26: val_loss did not improve from 30687.70312\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 12s/step - loss: 10807.8008 - mean_squared_error: 10807.8008 - val_loss: 33183.7109 - val_mean_squared_error: 33183.7109\n",
      "Epoch 27/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 10550.2725 - mean_squared_error: 10550.2725 \n",
      "Epoch 27: val_loss improved from 30687.70312 to 29683.89453, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 12s/step - loss: 10521.0566 - mean_squared_error: 10521.0566 - val_loss: 29683.8945 - val_mean_squared_error: 29683.8945\n",
      "Epoch 28/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 9602.4492 - mean_squared_error: 9602.4492 \n",
      "Epoch 28: val_loss improved from 29683.89453 to 28637.23828, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 12s/step - loss: 9634.4268 - mean_squared_error: 9634.4268 - val_loss: 28637.2383 - val_mean_squared_error: 28637.2383\n",
      "Epoch 29/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 10413.1416 - mean_squared_error: 10413.1416 \n",
      "Epoch 29: val_loss improved from 28637.23828 to 20310.59570, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 12s/step - loss: 10366.2197 - mean_squared_error: 10366.2197 - val_loss: 20310.5957 - val_mean_squared_error: 20310.5957\n",
      "Epoch 30/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 9190.2217 - mean_squared_error: 9190.2217 \n",
      "Epoch 30: val_loss did not improve from 20310.59570\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 12s/step - loss: 9205.8359 - mean_squared_error: 9205.8359 - val_loss: 24940.8027 - val_mean_squared_error: 24940.8027\n",
      "Epoch 31/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 11408.6758 - mean_squared_error: 11408.6758 \n",
      "Epoch 31: val_loss did not improve from 20310.59570\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 11s/step - loss: 11383.3896 - mean_squared_error: 11383.3896 - val_loss: 20855.4004 - val_mean_squared_error: 20855.4004\n",
      "Epoch 32/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 9197.8369 - mean_squared_error: 9197.8369 \n",
      "Epoch 32: val_loss improved from 20310.59570 to 19053.08203, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 12s/step - loss: 9212.1230 - mean_squared_error: 9212.1230 - val_loss: 19053.0820 - val_mean_squared_error: 19053.0820\n",
      "Epoch 33/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 9119.2422 - mean_squared_error: 9119.2422 \n",
      "Epoch 33: val_loss did not improve from 19053.08203\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 11s/step - loss: 9105.0186 - mean_squared_error: 9105.0186 - val_loss: 22110.5000 - val_mean_squared_error: 22110.5000\n",
      "Epoch 34/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 7586.1328 - mean_squared_error: 7586.1328 \n",
      "Epoch 34: val_loss improved from 19053.08203 to 16637.64844, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 12s/step - loss: 7614.6914 - mean_squared_error: 7614.6914 - val_loss: 16637.6484 - val_mean_squared_error: 16637.6484\n",
      "Epoch 35/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - loss: 7793.4150 - mean_squared_error: 7793.4150 \n",
      "Epoch 35: val_loss improved from 16637.64844 to 16252.70801, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 15s/step - loss: 7795.1851 - mean_squared_error: 7795.1851 - val_loss: 16252.7080 - val_mean_squared_error: 16252.7080\n",
      "Epoch 36/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 8461.1367 - mean_squared_error: 8461.1367 \n",
      "Epoch 36: val_loss did not improve from 16252.70801\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 13s/step - loss: 8431.9121 - mean_squared_error: 8431.9121 - val_loss: 24560.3594 - val_mean_squared_error: 24560.3594\n",
      "Epoch 37/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 7985.7290 - mean_squared_error: 7985.7290 \n",
      "Epoch 37: val_loss did not improve from 16252.70801\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 14s/step - loss: 7983.8828 - mean_squared_error: 7983.8828 - val_loss: 21260.0605 - val_mean_squared_error: 21260.0605\n",
      "Epoch 38/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - loss: 7803.3643 - mean_squared_error: 7803.3643 \n",
      "Epoch 38: val_loss did not improve from 16252.70801\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 13s/step - loss: 7821.7979 - mean_squared_error: 7821.7979 - val_loss: 20250.1699 - val_mean_squared_error: 20250.1699\n",
      "Epoch 39/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16s/step - loss: 8727.8887 - mean_squared_error: 8727.8887 \n",
      "Epoch 39: val_loss did not improve from 16252.70801\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 17s/step - loss: 8758.1484 - mean_squared_error: 8758.1484 - val_loss: 25216.4023 - val_mean_squared_error: 25216.4023\n",
      "Epoch 40/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - loss: 9642.0439 - mean_squared_error: 9642.0439 \n",
      "Epoch 40: val_loss improved from 16252.70801 to 13871.31543, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 17s/step - loss: 9600.6426 - mean_squared_error: 9600.6426 - val_loss: 13871.3154 - val_mean_squared_error: 13871.3154\n",
      "Epoch 41/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - loss: 7296.8638 - mean_squared_error: 7296.8638 \n",
      "Epoch 41: val_loss did not improve from 13871.31543\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 21s/step - loss: 7310.4907 - mean_squared_error: 7310.4907 - val_loss: 17271.2246 - val_mean_squared_error: 17271.2246\n",
      "Epoch 42/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - loss: 7697.7192 - mean_squared_error: 7697.7192 \n",
      "Epoch 42: val_loss improved from 13871.31543 to 13720.55469, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 13s/step - loss: 7698.2842 - mean_squared_error: 7698.2842 - val_loss: 13720.5547 - val_mean_squared_error: 13720.5547\n",
      "Epoch 43/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - loss: 7812.2090 - mean_squared_error: 7812.2090 \n",
      "Epoch 43: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 13s/step - loss: 7795.2012 - mean_squared_error: 7795.2012 - val_loss: 14858.7158 - val_mean_squared_error: 14858.7158\n",
      "Epoch 44/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - loss: 7239.0908 - mean_squared_error: 7239.0908 \n",
      "Epoch 44: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 13s/step - loss: 7243.4595 - mean_squared_error: 7243.4595 - val_loss: 16544.5488 - val_mean_squared_error: 16544.5488\n",
      "Epoch 45/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - loss: 6946.5542 - mean_squared_error: 6946.5542 \n",
      "Epoch 45: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 13s/step - loss: 6965.7739 - mean_squared_error: 6965.7739 - val_loss: 17465.9375 - val_mean_squared_error: 17465.9375\n",
      "Epoch 46/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - loss: 8339.5488 - mean_squared_error: 8339.5488 \n",
      "Epoch 46: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 13s/step - loss: 8350.3486 - mean_squared_error: 8350.3486 - val_loss: 19922.8242 - val_mean_squared_error: 19922.8242\n",
      "Epoch 47/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - loss: 11792.9717 - mean_squared_error: 11792.9717 \n",
      "Epoch 47: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 13s/step - loss: 11762.3047 - mean_squared_error: 11762.3047 - val_loss: 24529.0000 - val_mean_squared_error: 24529.0000\n",
      "Epoch 48/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 11541.0889 - mean_squared_error: 11541.0889 \n",
      "Epoch 48: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 14s/step - loss: 11505.9844 - mean_squared_error: 11505.9844 - val_loss: 22080.0977 - val_mean_squared_error: 22080.0977\n",
      "Epoch 49/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 8390.1025 - mean_squared_error: 8390.1025 \n",
      "Epoch 49: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 14s/step - loss: 8368.4561 - mean_squared_error: 8368.4561 - val_loss: 20567.0352 - val_mean_squared_error: 20567.0352\n",
      "Epoch 50/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16s/step - loss: 7021.3428 - mean_squared_error: 7021.3428 \n",
      "Epoch 50: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 18s/step - loss: 7040.9453 - mean_squared_error: 7040.9453 - val_loss: 20840.6836 - val_mean_squared_error: 20840.6836\n",
      "Epoch 51/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - loss: 7059.8691 - mean_squared_error: 7059.8691 \n",
      "Epoch 51: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 17s/step - loss: 7068.8354 - mean_squared_error: 7068.8354 - val_loss: 17428.4609 - val_mean_squared_error: 17428.4609\n",
      "Epoch 52/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - loss: 7315.6553 - mean_squared_error: 7315.6553 \n",
      "Epoch 52: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 24s/step - loss: 7292.8232 - mean_squared_error: 7292.8232 - val_loss: 15705.1436 - val_mean_squared_error: 15705.1436\n",
      "Epoch 53/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - loss: 6220.6475 - mean_squared_error: 6220.6475 \n",
      "Epoch 53: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 24s/step - loss: 6237.8374 - mean_squared_error: 6237.8374 - val_loss: 16828.9688 - val_mean_squared_error: 16828.9688\n",
      "Epoch 54/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - loss: 6498.3950 - mean_squared_error: 6498.3950 \n",
      "Epoch 54: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 24s/step - loss: 6502.9878 - mean_squared_error: 6502.9878 - val_loss: 16746.5039 - val_mean_squared_error: 16746.5039\n",
      "Epoch 55/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - loss: 7196.8076 - mean_squared_error: 7196.8076 \n",
      "Epoch 55: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 24s/step - loss: 7173.6152 - mean_squared_error: 7173.6152 - val_loss: 14879.5801 - val_mean_squared_error: 14879.5801\n",
      "Epoch 56/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21s/step - loss: 6268.6030 - mean_squared_error: 6268.6030 \n",
      "Epoch 56: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 23s/step - loss: 6281.2856 - mean_squared_error: 6281.2856 - val_loss: 13829.3926 - val_mean_squared_error: 13829.3926\n",
      "Epoch 57/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25s/step - loss: 7901.1118 - mean_squared_error: 7901.1118 \n",
      "Epoch 57: val_loss did not improve from 13720.55469\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 27s/step - loss: 7874.0283 - mean_squared_error: 7874.0283 - val_loss: 16103.1797 - val_mean_squared_error: 16103.1797\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, mode='min', verbose=verbose)\n",
    "best = ModelCheckpoint(\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True, \n",
    "    save_weights_only=False, \n",
    "    filepath='./model/best_multimodal_weights.keras'\n",
    ")\n",
    "\n",
    "hist_multimodal = multimodal_model.fit(\n",
    "    [x_train_imgs, x_train_std],\n",
    "    y_train,                   \n",
    "    epochs=epochs,\n",
    "    batch_size = 256,\n",
    "    validation_data=([x_test_imgs, x_test_std], y_test),\n",
    "    callbacks=[stop, best]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
