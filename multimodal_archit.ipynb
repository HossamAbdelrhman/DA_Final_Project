{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError, MeanSquaredError\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, History, LearningRateScheduler\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling2D, Activation, Dropout, Dense, Input, Multiply, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load listing data\n",
    "listing_data = pd.read_csv('./data/listings.csv')\n",
    "\n",
    "# copy the data frame to apply changes savely\n",
    "new_listing_df = listing_data.copy()\n",
    "\n",
    "# data pre-processing\n",
    "# drop identifiers & unrequired columns\n",
    "drop_cols_list = [\n",
    "    'scrape_id', 'name', 'description', 'neighborhood_overview',\n",
    "    'picture_url', 'host_id', 'host_url', 'host_name', 'host_location', 'host_about',\n",
    "    'host_response_time', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_verifications',\n",
    "    'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
    "    'bathrooms_text', 'amenities', 'license', 'last_scraped', 'source', 'host_since', 'calendar_updated',\n",
    "    'calendar_last_scraped', 'first_review', 'last_review'\n",
    "]\n",
    "new_listing_df.drop(drop_cols_list, axis=1, inplace=True)\n",
    "\n",
    "# drop records with null [price, host_response_rate, host_acceptance_rate] value\n",
    "new_listing_df = new_listing_df.dropna(axis=0, subset=['price', 'host_response_rate', 'host_acceptance_rate'])\n",
    "\n",
    "# encode T/F columns \n",
    "tf_columns = [\n",
    "    'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified',\n",
    "    'has_availability', 'instant_bookable',     \n",
    "]\n",
    "label_encoder = LabelEncoder().fit(new_listing_df['host_is_superhost'])\n",
    "for col in tf_columns:\n",
    "    new_listing_df[col] = label_encoder.transform(new_listing_df[col])\n",
    "\n",
    "# fill null numerical values with median\n",
    "cols_to_fill_miss_values = [\n",
    "    'reviews_per_month', 'review_scores_value', 'review_scores_location', 'review_scores_communication',\n",
    "    'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_accuracy', 'review_scores_rating', 'beds',\n",
    "    'bedrooms', 'bathrooms', \n",
    "]\n",
    "for col in cols_to_fill_miss_values:\n",
    "    new_listing_df[col] = new_listing_df[col].fillna(new_listing_df[col].median())\n",
    "\n",
    "# convert object values to numerical values\n",
    "obj_cols = ['host_response_rate', 'host_acceptance_rate']\n",
    "for col in obj_cols:\n",
    "    new_listing_df[col] = pd.to_numeric(new_listing_df[col].map(lambda val: val.replace('%', '')))\n",
    "new_listing_df['price'] = pd.to_numeric(new_listing_df['price'].map(lambda val: val.replace('$', '').replace(',', '')))\n",
    "\n",
    "\n",
    "# all two columns('images_names', 'images_No') with none values\n",
    "new_listing_df['images_names'] = [None for _ in range(len(new_listing_df))]\n",
    "new_listing_df['images_No'] = [ 0 for _ in range(len(new_listing_df))]\n",
    "\n",
    "new_listing_df.to_csv('./data/preprocessed_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19142 entries, 1 to 37763\n",
      "Data columns (total 46 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            19142 non-null  int64  \n",
      " 1   host_response_rate                            19142 non-null  int64  \n",
      " 2   host_acceptance_rate                          19142 non-null  int64  \n",
      " 3   host_is_superhost                             19142 non-null  int32  \n",
      " 4   host_listings_count                           19142 non-null  float64\n",
      " 5   host_total_listings_count                     19142 non-null  float64\n",
      " 6   host_has_profile_pic                          19142 non-null  int32  \n",
      " 7   host_identity_verified                        19142 non-null  int32  \n",
      " 8   latitude                                      19142 non-null  float64\n",
      " 9   longitude                                     19142 non-null  float64\n",
      " 10  accommodates                                  19142 non-null  int64  \n",
      " 11  bathrooms                                     19142 non-null  float64\n",
      " 12  bedrooms                                      19142 non-null  float64\n",
      " 13  beds                                          19142 non-null  float64\n",
      " 14  price                                         19142 non-null  float64\n",
      " 15  minimum_nights                                19142 non-null  int64  \n",
      " 16  maximum_nights                                19142 non-null  int64  \n",
      " 17  minimum_minimum_nights                        19142 non-null  float64\n",
      " 18  maximum_minimum_nights                        19142 non-null  float64\n",
      " 19  minimum_maximum_nights                        19142 non-null  float64\n",
      " 20  maximum_maximum_nights                        19142 non-null  float64\n",
      " 21  minimum_nights_avg_ntm                        19142 non-null  float64\n",
      " 22  maximum_nights_avg_ntm                        19142 non-null  float64\n",
      " 23  has_availability                              19142 non-null  int32  \n",
      " 24  availability_30                               19142 non-null  int64  \n",
      " 25  availability_60                               19142 non-null  int64  \n",
      " 26  availability_90                               19142 non-null  int64  \n",
      " 27  availability_365                              19142 non-null  int64  \n",
      " 28  number_of_reviews                             19142 non-null  int64  \n",
      " 29  number_of_reviews_ltm                         19142 non-null  int64  \n",
      " 30  number_of_reviews_l30d                        19142 non-null  int64  \n",
      " 31  review_scores_rating                          19142 non-null  float64\n",
      " 32  review_scores_accuracy                        19142 non-null  float64\n",
      " 33  review_scores_cleanliness                     19142 non-null  float64\n",
      " 34  review_scores_checkin                         19142 non-null  float64\n",
      " 35  review_scores_communication                   19142 non-null  float64\n",
      " 36  review_scores_location                        19142 non-null  float64\n",
      " 37  review_scores_value                           19142 non-null  float64\n",
      " 38  instant_bookable                              19142 non-null  int32  \n",
      " 39  calculated_host_listings_count                19142 non-null  int64  \n",
      " 40  calculated_host_listings_count_entire_homes   19142 non-null  int64  \n",
      " 41  calculated_host_listings_count_private_rooms  19142 non-null  int64  \n",
      " 42  calculated_host_listings_count_shared_rooms   19142 non-null  int64  \n",
      " 43  reviews_per_month                             19142 non-null  float64\n",
      " 44  images_names                                  0 non-null      object \n",
      " 45  images_No                                     19142 non-null  int64  \n",
      "dtypes: float64(22), int32(5), int64(18), object(1)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "new_listing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### We need to fill new columns (images_names, images_No) using script_of_image_scraping file first then follow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hossam Aboouf\\AppData\\Local\\Temp\\ipykernel_26500\\2504157448.py:3: DtypeWarning: Columns (46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('./data/preprocessed_listings.csv')\n"
     ]
    }
   ],
   "source": [
    "# read and prepare data\n",
    "img_size = (224, 224)\n",
    "data = pd.read_csv('./data/preprocessed_listings.csv')\n",
    "data = data.drop('Unnamed: 0', axis=1)[data['images_No'] == 5] # drop 'Unnamed: 0' column and use only recordes with images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1268 entries, 0 to 1323\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            1268 non-null   int64  \n",
      " 1   listing_url                                   1268 non-null   object \n",
      " 2   host_response_rate                            1268 non-null   int64  \n",
      " 3   host_acceptance_rate                          1268 non-null   int64  \n",
      " 4   host_is_superhost                             1268 non-null   int64  \n",
      " 5   host_listings_count                           1268 non-null   float64\n",
      " 6   host_total_listings_count                     1268 non-null   float64\n",
      " 7   host_has_profile_pic                          1268 non-null   int64  \n",
      " 8   host_identity_verified                        1268 non-null   int64  \n",
      " 9   latitude                                      1268 non-null   float64\n",
      " 10  longitude                                     1268 non-null   float64\n",
      " 11  accommodates                                  1268 non-null   int64  \n",
      " 12  bathrooms                                     1268 non-null   float64\n",
      " 13  bedrooms                                      1268 non-null   float64\n",
      " 14  beds                                          1268 non-null   float64\n",
      " 15  price                                         1268 non-null   float64\n",
      " 16  minimum_nights                                1268 non-null   int64  \n",
      " 17  maximum_nights                                1268 non-null   int64  \n",
      " 18  minimum_minimum_nights                        1268 non-null   float64\n",
      " 19  maximum_minimum_nights                        1268 non-null   float64\n",
      " 20  minimum_maximum_nights                        1268 non-null   float64\n",
      " 21  maximum_maximum_nights                        1268 non-null   float64\n",
      " 22  minimum_nights_avg_ntm                        1268 non-null   float64\n",
      " 23  maximum_nights_avg_ntm                        1268 non-null   float64\n",
      " 24  has_availability                              1268 non-null   int64  \n",
      " 25  availability_30                               1268 non-null   int64  \n",
      " 26  availability_60                               1268 non-null   int64  \n",
      " 27  availability_90                               1268 non-null   int64  \n",
      " 28  availability_365                              1268 non-null   int64  \n",
      " 29  number_of_reviews                             1268 non-null   int64  \n",
      " 30  number_of_reviews_ltm                         1268 non-null   int64  \n",
      " 31  number_of_reviews_l30d                        1268 non-null   int64  \n",
      " 32  review_scores_rating                          1268 non-null   float64\n",
      " 33  review_scores_accuracy                        1268 non-null   float64\n",
      " 34  review_scores_cleanliness                     1268 non-null   float64\n",
      " 35  review_scores_checkin                         1268 non-null   float64\n",
      " 36  review_scores_communication                   1268 non-null   float64\n",
      " 37  review_scores_location                        1268 non-null   float64\n",
      " 38  review_scores_value                           1268 non-null   float64\n",
      " 39  instant_bookable                              1268 non-null   int64  \n",
      " 40  calculated_host_listings_count                1268 non-null   int64  \n",
      " 41  calculated_host_listings_count_entire_homes   1268 non-null   int64  \n",
      " 42  calculated_host_listings_count_private_rooms  1268 non-null   int64  \n",
      " 43  calculated_host_listings_count_shared_rooms   1268 non-null   int64  \n",
      " 44  reviews_per_month                             1268 non-null   float64\n",
      " 45  images_names                                  1268 non-null   object \n",
      " 46  images_No                                     1268 non-null   int64  \n",
      "dtypes: float64(22), int64(23), object(2)\n",
      "memory usage: 475.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune CV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_and_prices(df):\n",
    "    paths = []\n",
    "    prices = []\n",
    "    for _, row in df.iterrows():\n",
    "        for name in row['images_names'].split(','):\n",
    "            paths.append(f'./images/{name}')\n",
    "            prices.append(row['price'])\n",
    "    return paths, prices\n",
    "\n",
    "def customise_data(data):\n",
    "    x_train, x_test, _, _ = train_test_split(data, [0 for _ in range(len(data))], test_size=.2, shuffle=True, random_state=303)\n",
    "    paths, prices = get_paths_and_prices(x_train)\n",
    "    dict_ = {\n",
    "        'imgs': paths,\n",
    "        'prices': prices\n",
    "    }\n",
    "    new_x_train = pd.DataFrame(dict_)\n",
    "\n",
    "    paths, prices = get_paths_and_prices(x_test)\n",
    "    dict_ = {\n",
    "        'imgs': paths,\n",
    "        'prices': prices\n",
    "    }\n",
    "    new_x_test = pd.DataFrame(dict_)\n",
    "\n",
    "    return new_x_train, new_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ avg_pool                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_472         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ avg_pool                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_472         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m131,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,942,177</span> (83.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,942,177\u001b[0m (83.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,297</span> (528.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m135,297\u001b[0m (528.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,806,880</span> (83.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,806,880\u001b[0m (83.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "Found 5070 validated image filenames.\n",
      "Found 1270 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hossam Aboouf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1263: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hossam Aboouf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1273: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hossam Aboouf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 38124.3594 - mse: 38319.4883\n",
      "Epoch 1: val_loss improved from inf to 37123.03516, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 4s/step - loss: 38085.5391 - mse: 38280.3906 - val_loss: 37123.0352 - val_mse: 37293.1758\n",
      "Epoch 2/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 34927.4141 - mse: 34932.2891\n",
      "Epoch 2: val_loss improved from 37123.03516 to 30626.72852, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 3s/step - loss: 34898.8828 - mse: 34903.9922 - val_loss: 30626.7285 - val_mse: 30866.5586\n",
      "Epoch 3/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 34807.6680 - mse: 35101.1484\n",
      "Epoch 3: val_loss did not improve from 30626.72852\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 4s/step - loss: 34764.9570 - mse: 35058.0742 - val_loss: 30884.6191 - val_mse: 31056.0723\n",
      "Epoch 4/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 30268.4453 - mse: 30483.8945\n",
      "Epoch 4: val_loss did not improve from 30626.72852\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 4s/step - loss: 30292.2656 - mse: 30507.4902 - val_loss: 31016.6289 - val_mse: 31200.2754\n",
      "Epoch 5/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 31794.1895 - mse: 32008.0664\n",
      "Epoch 5: val_loss did not improve from 30626.72852\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 3s/step - loss: 31793.2949 - mse: 32006.5020 - val_loss: 31128.3320 - val_mse: 31159.6406\n",
      "Epoch 6/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 30386.4082 - mse: 30448.8730\n",
      "Epoch 6: val_loss improved from 30626.72852 to 30587.16797, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 4s/step - loss: 30394.4766 - mse: 30458.1270 - val_loss: 30587.1680 - val_mse: 30813.1289\n",
      "Epoch 7/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 34167.2266 - mse: 32117.9512\n",
      "Epoch 7: val_loss improved from 30587.16797 to 30545.38477, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 3s/step - loss: 34196.4414 - mse: 32120.3125 - val_loss: 30545.3848 - val_mse: 30736.7793\n",
      "Epoch 8/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 33775.7969 - mse: 33610.4727\n",
      "Epoch 8: val_loss did not improve from 30545.38477\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 3s/step - loss: 33746.5664 - mse: 33581.0391 - val_loss: 33188.3125 - val_mse: 33473.3242\n",
      "Epoch 9/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 32794.1680 - mse: 32821.7461\n",
      "Epoch 9: val_loss did not improve from 30545.38477\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 3s/step - loss: 32775.0312 - mse: 32805.0312 - val_loss: 30844.1152 - val_mse: 30910.2891\n",
      "Epoch 10/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 27937.2695 - mse: 28001.9570\n",
      "Epoch 10: val_loss improved from 30545.38477 to 30533.91602, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 4s/step - loss: 27977.5391 - mse: 28043.0547 - val_loss: 30533.9160 - val_mse: 30651.9707\n",
      "Epoch 11/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 36182.9492 - mse: 36090.4805\n",
      "Epoch 11: val_loss improved from 30533.91602 to 30478.33984, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - loss: 36129.4961 - mse: 36036.6211 - val_loss: 30478.3398 - val_mse: 30668.3672\n",
      "Epoch 12/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 36805.9922 - mse: 37428.8867\n",
      "Epoch 12: val_loss did not improve from 30478.33984\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - loss: 36731.9844 - mse: 37349.4805 - val_loss: 30547.9258 - val_mse: 30788.8477\n",
      "Epoch 13/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 27001.3711 - mse: 27071.5762\n",
      "Epoch 13: val_loss improved from 30478.33984 to 30411.42188, saving model to ./model/best_iv3_weights.keras\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - loss: 27049.7480 - mse: 27121.4766 - val_loss: 30411.4219 - val_mse: 30639.2617\n",
      "Epoch 14/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 36021.9844 - mse: 36034.0312\n",
      "Epoch 14: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - loss: 35963.3477 - mse: 35976.1836 - val_loss: 32989.9766 - val_mse: 30795.2227\n",
      "Epoch 15/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 27693.1426 - mse: 27807.5605\n",
      "Epoch 15: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 2s/step - loss: 27736.3711 - mse: 27852.5664 - val_loss: 30981.9941 - val_mse: 31141.3594\n",
      "Epoch 16/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 28571.7227 - mse: 28728.4512\n",
      "Epoch 16: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 2s/step - loss: 28603.0566 - mse: 28760.6035 - val_loss: 31245.1934 - val_mse: 31270.2949\n",
      "Epoch 17/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 34076.4609 - mse: 34386.6562\n",
      "Epoch 17: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - loss: 34039.9375 - mse: 34349.1680 - val_loss: 31073.8789 - val_mse: 31324.9043\n",
      "Epoch 18/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 34621.9141 - mse: 35037.2461\n",
      "Epoch 18: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - loss: 34583.7656 - mse: 34997.0156 - val_loss: 32095.2305 - val_mse: 32143.6582\n",
      "Epoch 19/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 31719.0078 - mse: 31695.5840\n",
      "Epoch 19: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 2s/step - loss: 31719.8828 - mse: 31696.5957 - val_loss: 34304.4414 - val_mse: 34443.8945\n",
      "Epoch 20/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 38901.8711 - mse: 38500.2461\n",
      "Epoch 20: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - loss: 38815.5664 - mse: 38415.1172 - val_loss: 32251.3281 - val_mse: 31882.5820\n",
      "Epoch 21/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 34038.5781 - mse: 34908.5312\n",
      "Epoch 21: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - loss: 34001.6367 - mse: 34864.0234 - val_loss: 30906.0723 - val_mse: 31124.5508\n",
      "Epoch 22/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985ms/step - loss: 31703.2500 - mse: 31608.1855\n",
      "Epoch 22: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 2s/step - loss: 31698.5488 - mse: 31604.0801 - val_loss: 31489.8086 - val_mse: 31531.1211\n",
      "Epoch 23/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990ms/step - loss: 34605.8477 - mse: 34615.0781\n",
      "Epoch 23: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 2s/step - loss: 34562.7109 - mse: 34572.1562 - val_loss: 34693.3789 - val_mse: 30800.8652\n",
      "Epoch 24/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999ms/step - loss: 33160.8281 - mse: 30333.2031\n",
      "Epoch 24: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 2s/step - loss: 33195.1523 - mse: 30351.6875 - val_loss: 30640.3789 - val_mse: 30696.9883\n",
      "Epoch 25/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983ms/step - loss: 29473.7148 - mse: 29491.4961\n",
      "Epoch 25: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 2s/step - loss: 29493.8340 - mse: 29513.1348 - val_loss: 30629.8691 - val_mse: 30847.4609\n",
      "Epoch 26/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 35039.4609 - mse: 35181.1797\n",
      "Epoch 26: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 2s/step - loss: 34996.6719 - mse: 35138.4961 - val_loss: 30776.6133 - val_mse: 30799.2617\n",
      "Epoch 27/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 33637.2734 - mse: 33634.1602\n",
      "Epoch 27: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 2s/step - loss: 33606.0117 - mse: 33601.4102 - val_loss: 31404.8906 - val_mse: 31138.5508\n",
      "Epoch 28/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 32104.2949 - mse: 32092.0195\n",
      "Epoch 28: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 2s/step - loss: 32110.4980 - mse: 32094.3770 - val_loss: 30542.2344 - val_mse: 30791.9023\n",
      "Epoch 29/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 32434.4238 - mse: 32628.9688\n",
      "Epoch 29: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 2s/step - loss: 32422.5039 - mse: 32617.6738 - val_loss: 30835.1465 - val_mse: 31080.1328\n",
      "Epoch 30/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 33331.3828 - mse: 33464.9023\n",
      "Epoch 30: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 2s/step - loss: 33308.9844 - mse: 33442.1523 - val_loss: 31500.2090 - val_mse: 31677.2578\n",
      "Epoch 31/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 33223.5312 - mse: 33504.3984\n",
      "Epoch 31: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 2s/step - loss: 33196.6680 - mse: 33476.8633 - val_loss: 30627.4590 - val_mse: 30871.2051\n",
      "Epoch 32/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 27702.1992 - mse: 27759.5742\n",
      "Epoch 32: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 2s/step - loss: 27747.4375 - mse: 27806.8633 - val_loss: 30717.8281 - val_mse: 30898.5371\n",
      "Epoch 33/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 26681.7051 - mse: 27103.4746\n",
      "Epoch 33: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - loss: 26737.9453 - mse: 27157.6387 - val_loss: 30553.4883 - val_mse: 30654.1387\n",
      "Epoch 34/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 32320.0859 - mse: 32350.3926\n",
      "Epoch 34: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - loss: 32319.7773 - mse: 32350.9453 - val_loss: 30947.9941 - val_mse: 31138.3672\n",
      "Epoch 35/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 30607.5117 - mse: 30713.6660\n",
      "Epoch 35: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - loss: 30613.2266 - mse: 30721.1855 - val_loss: 30632.5723 - val_mse: 30744.3750\n",
      "Epoch 36/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 30775.0684 - mse: 30826.0898\n",
      "Epoch 36: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - loss: 30775.5957 - mse: 30828.6211 - val_loss: 31456.5352 - val_mse: 31432.5547\n",
      "Epoch 37/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 33458.1797 - mse: 33519.8789\n",
      "Epoch 37: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - loss: 33435.3711 - mse: 33499.0977 - val_loss: 31362.6445 - val_mse: 31218.5684\n",
      "Epoch 38/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 36961.3711 - mse: 36150.4453\n",
      "Epoch 38: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - loss: 36895.8320 - mse: 36089.9219 - val_loss: 31140.1055 - val_mse: 31331.3379\n",
      "Epoch 39/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 26331.6328 - mse: 25674.4707\n",
      "Epoch 39: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - loss: 26398.0391 - mse: 25743.9258 - val_loss: 30678.9102 - val_mse: 30737.5586\n",
      "Epoch 40/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 33807.9648 - mse: 33874.8281\n",
      "Epoch 40: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - loss: 33776.8047 - mse: 33842.6836 - val_loss: 30703.8184 - val_mse: 30968.1680\n",
      "Epoch 41/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 32660.6621 - mse: 32691.5312\n",
      "Epoch 41: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - loss: 32640.1719 - mse: 32673.1973 - val_loss: 31536.5410 - val_mse: 31780.1113\n",
      "Epoch 42/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 29869.0430 - mse: 29839.5176\n",
      "Epoch 42: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - loss: 29885.1094 - mse: 29854.5273 - val_loss: 30627.4590 - val_mse: 30853.7363\n",
      "Epoch 43/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 29274.6855 - mse: 29359.8184\n",
      "Epoch 43: val_loss did not improve from 30411.42188\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - loss: 29299.3906 - mse: 29386.0098 - val_loss: 30638.4883 - val_mse: 30707.0742\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to synchronously create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 73\u001b[0m\n\u001b[0;32m     54\u001b[0m img_test \u001b[38;5;241m=\u001b[39m test_img_generator\u001b[38;5;241m.\u001b[39mflow_from_dataframe(\n\u001b[0;32m     55\u001b[0m         dataframe\u001b[38;5;241m=\u001b[39mtest_df,\n\u001b[0;32m     56\u001b[0m         x_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[0;32m     62\u001b[0m         )\n\u001b[0;32m     64\u001b[0m hist \u001b[38;5;241m=\u001b[39m Incep3_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     65\u001b[0m     imgs_train, \n\u001b[0;32m     66\u001b[0m     validation_data \u001b[38;5;241m=\u001b[39m imgs_train,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[stop, best]\n\u001b[0;32m     71\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m \u001b[43mIncep3_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./model/last_iv3_model_simple.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hossam Aboouf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Hossam Aboouf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h5py\\_hl\\group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32mc:\\Users\\Hossam Aboouf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h5py\\_hl\\dataset.py:163\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[1;32m--> 163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m    166\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5d.pyx:137\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to synchronously create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "train_df, test_df = customise_data(data)\n",
    "\n",
    "# fine tune CV model (Inception v3)\n",
    "# Create the model\n",
    "img_input = Input(shape=(img_size[0], img_size[1], 3))\n",
    "Incep3_base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_tensor=img_input)\n",
    "\n",
    "# stop weight update\n",
    "for layer in Incep3_base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# update inseption model strcture by adding some layers to make it deal with our price prediction task\n",
    "Incep3_base_model = Incep3_base_model(img_input, training=False)\n",
    "Incep3_base_model = GlobalAveragePooling2D(name=\"avg_pool\")(Incep3_base_model)\n",
    "Incep3_base_model = BatchNormalization()(Incep3_base_model)\n",
    "Incep3_base_model = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense_hidden_cv')(Incep3_base_model)\n",
    "Incep3_base_model = Dense(1, activation='linear')(Incep3_base_model)\n",
    "Incep3_model = Model(inputs=img_input, outputs=Incep3_base_model)\n",
    "\n",
    "# initialize hyper-prameters\n",
    "lr = 0.1 \n",
    "verbose = 1\n",
    "epochs = 100\n",
    "batch_size = 64 \n",
    "        \n",
    "Incep3_model.compile(optimizer=Adam(learning_rate=lr, epsilon=1), metrics=['mse'], loss='mse')\n",
    "Incep3_model.summary()\n",
    "plot_model(Incep3_model, show_shapes=True, to_file='./inceptionV3_model_image.png')\n",
    "stop = EarlyStopping(monitor=\"val_loss\", patience=30, restore_best_weights=True, mode='min', verbose=verbose)\n",
    "best = ModelCheckpoint(\n",
    "    filepath='./model/best_iv3_weights.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=verbose,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "train_img_generator = ImageDataGenerator(\n",
    "    brightness_range=(0.75, 1),\n",
    "    shear_range=0.1,\n",
    "    zoom_range=[0.50, 1],\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_img_generator = ImageDataGenerator(rescale=1.0)\n",
    "\n",
    "imgs_train = train_img_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col=\"imgs\",  \n",
    "        y_col=\"prices\",  \n",
    "        class_mode=\"raw\",  \n",
    "        color_mode='rgb',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size\n",
    "        )\n",
    "imgs_test = test_img_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col=\"imgs\",\n",
    "        y_col=\"prices\",\n",
    "        class_mode=\"raw\",\n",
    "        color_mode='rgb',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size\n",
    "        )\n",
    "\n",
    "hist = Incep3_model.fit(\n",
    "    imgs_train, \n",
    "    validation_data = imgs_test,\n",
    "    batch_size=batch_size,\n",
    "    verbose=verbose,\n",
    "    epochs=epochs,\n",
    "    callbacks=[stop, best]\n",
    ")\n",
    "\n",
    "Incep3_model.save('./model/last_iv3_model_simple.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune model for structure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read, prepare and split data\n",
    "data_std = data.drop(['id', 'listing_url', 'images_names', 'images_No'], axis=1)\n",
    "y_data_std = data_std['price']\n",
    "x_data_std = data_std.drop('price', axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data_std, y_data_std, test_size=.2, shuffle=True, random_state=303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_std (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_std (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,075</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_std (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │         \u001b[38;5;34m1,806\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden_std (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,075\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m26\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,907</span> (11.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,907\u001b[0m (11.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,907</span> (11.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,907\u001b[0m (11.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# build std model (simple MLP algorithm)\n",
    "input_layer = Input(shape=(x_train.shape[1],), name='input_layer_std')\n",
    "base_model = Dense(x_train.shape[1], activation='relu', kernel_initializer='he_normal')(input_layer)\n",
    "base_model = Dense(25, activation='relu', name='dense_hidden_std')(base_model)\n",
    "output_layer = Dense(1, activation='linear')(base_model)\n",
    "model_std = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "print(model_std.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "Epoch 1/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 958ms/step - loss: 60376.2695 - mean_squared_error: 60376.2695\n",
      "Epoch 1: val_loss improved from inf to 69128.20312, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 57300.7031 - mean_squared_error: 57300.7031 - val_loss: 69128.2031 - val_mean_squared_error: 69128.2031\n",
      "Epoch 2/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 25399.1875 - mean_squared_error: 25399.1875\n",
      "Epoch 2: val_loss did not improve from 69128.20312\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30988.6953 - mean_squared_error: 30988.6953 - val_loss: 76306.3750 - val_mean_squared_error: 76306.3750\n",
      "Epoch 3/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 20656.9473 - mean_squared_error: 20656.9473\n",
      "Epoch 3: val_loss improved from 69128.20312 to 67102.72656, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32664.3555 - mean_squared_error: 32664.3555 - val_loss: 67102.7266 - val_mean_squared_error: 67102.7266\n",
      "Epoch 4/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10212.3564 - mean_squared_error: 10212.3564\n",
      "Epoch 4: val_loss did not improve from 67102.72656\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25363.0488 - mean_squared_error: 25363.0488 - val_loss: 69441.5000 - val_mean_squared_error: 69441.5000\n",
      "Epoch 5/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5937.9121 - mean_squared_error: 5937.9121\n",
      "Epoch 5: val_loss did not improve from 67102.72656\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28196.8613 - mean_squared_error: 28196.8613 - val_loss: 75254.5078 - val_mean_squared_error: 75254.5078\n",
      "Epoch 6/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 133558.7031 - mean_squared_error: 133558.7031\n",
      "Epoch 6: val_loss did not improve from 67102.72656\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38978.7812 - mean_squared_error: 38978.7812 - val_loss: 69656.5391 - val_mean_squared_error: 69656.5391\n",
      "Epoch 7/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 24944.0352 - mean_squared_error: 24944.0352\n",
      "Epoch 7: val_loss improved from 67102.72656 to 64212.55859, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28892.1816 - mean_squared_error: 28892.1816 - val_loss: 64212.5586 - val_mean_squared_error: 64212.5586\n",
      "Epoch 8/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 14902.7246 - mean_squared_error: 14902.7246\n",
      "Epoch 8: val_loss did not improve from 64212.55859\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25575.2344 - mean_squared_error: 25575.2344 - val_loss: 72403.7891 - val_mean_squared_error: 72403.7891\n",
      "Epoch 9/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 28836.7695 - mean_squared_error: 28836.7695\n",
      "Epoch 9: val_loss improved from 64212.55859 to 63054.25781, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27858.2148 - mean_squared_error: 27858.2148 - val_loss: 63054.2578 - val_mean_squared_error: 63054.2578\n",
      "Epoch 10/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10363.1436 - mean_squared_error: 10363.1436\n",
      "Epoch 10: val_loss did not improve from 63054.25781\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23244.8770 - mean_squared_error: 23244.8770 - val_loss: 64036.5469 - val_mean_squared_error: 64036.5469\n",
      "Epoch 11/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 118258.1094 - mean_squared_error: 118258.1094\n",
      "Epoch 11: val_loss did not improve from 63054.25781\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40941.6758 - mean_squared_error: 40941.6758 - val_loss: 63813.0625 - val_mean_squared_error: 63813.0625\n",
      "Epoch 12/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 9223.6621 - mean_squared_error: 9223.6621\n",
      "Epoch 12: val_loss did not improve from 63054.25781\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26865.0684 - mean_squared_error: 26865.0684 - val_loss: 63170.2188 - val_mean_squared_error: 63170.2188\n",
      "Epoch 13/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13048.2246 - mean_squared_error: 13048.2246\n",
      "Epoch 13: val_loss improved from 63054.25781 to 62903.28906, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21759.0664 - mean_squared_error: 21759.0664 - val_loss: 62903.2891 - val_mean_squared_error: 62903.2891\n",
      "Epoch 14/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 17614.6641 - mean_squared_error: 17614.6641\n",
      "Epoch 14: val_loss did not improve from 62903.28906\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24682.5762 - mean_squared_error: 24682.5762 - val_loss: 63145.4531 - val_mean_squared_error: 63145.4531\n",
      "Epoch 15/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5293.8735 - mean_squared_error: 5293.8735\n",
      "Epoch 15: val_loss improved from 62903.28906 to 59604.27344, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30955.8320 - mean_squared_error: 30955.8320 - val_loss: 59604.2734 - val_mean_squared_error: 59604.2734\n",
      "Epoch 16/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 148200.2969 - mean_squared_error: 148200.2969\n",
      "Epoch 16: val_loss did not improve from 59604.27344\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34245.9648 - mean_squared_error: 34245.9648 - val_loss: 60487.7188 - val_mean_squared_error: 60487.7188\n",
      "Epoch 17/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 11657.4082 - mean_squared_error: 11657.4082\n",
      "Epoch 17: val_loss did not improve from 59604.27344\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22319.6816 - mean_squared_error: 22319.6816 - val_loss: 66089.9375 - val_mean_squared_error: 66089.9375\n",
      "Epoch 18/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10102.0391 - mean_squared_error: 10102.0391\n",
      "Epoch 18: val_loss did not improve from 59604.27344\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21328.9961 - mean_squared_error: 21328.9961 - val_loss: 61968.0078 - val_mean_squared_error: 61968.0078\n",
      "Epoch 19/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6407.8223 - mean_squared_error: 6407.8223\n",
      "Epoch 19: val_loss improved from 59604.27344 to 58214.98438, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17325.5215 - mean_squared_error: 17325.5215 - val_loss: 58214.9844 - val_mean_squared_error: 58214.9844\n",
      "Epoch 20/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 20798.3320 - mean_squared_error: 20798.3320\n",
      "Epoch 20: val_loss improved from 58214.98438 to 58031.30859, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26095.5176 - mean_squared_error: 26095.5176 - val_loss: 58031.3086 - val_mean_squared_error: 58031.3086\n",
      "Epoch 21/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 9174.2578 - mean_squared_error: 9174.2578\n",
      "Epoch 21: val_loss improved from 58031.30859 to 53700.88281, saving model to ./model/best_std_weights.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17689.3652 - mean_squared_error: 17689.3652 - val_loss: 53700.8828 - val_mean_squared_error: 53700.8828\n",
      "Epoch 22/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10170.4326 - mean_squared_error: 10170.4326\n",
      "Epoch 22: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16438.9746 - mean_squared_error: 16438.9746 - val_loss: 69589.8125 - val_mean_squared_error: 69589.8125\n",
      "Epoch 23/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 21316.3379 - mean_squared_error: 21316.3379\n",
      "Epoch 23: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22859.5781 - mean_squared_error: 22859.5781 - val_loss: 61611.7266 - val_mean_squared_error: 61611.7266\n",
      "Epoch 24/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 20167.3516 - mean_squared_error: 20167.3516\n",
      "Epoch 24: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18479.7656 - mean_squared_error: 18479.7656 - val_loss: 57583.3125 - val_mean_squared_error: 57583.3125\n",
      "Epoch 25/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 42079.0273 - mean_squared_error: 42079.0273\n",
      "Epoch 25: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18545.2754 - mean_squared_error: 18545.2754 - val_loss: 58123.5508 - val_mean_squared_error: 58123.5508\n",
      "Epoch 26/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 11399.1787 - mean_squared_error: 11399.1787\n",
      "Epoch 26: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17679.8184 - mean_squared_error: 17679.8184 - val_loss: 60570.0469 - val_mean_squared_error: 60570.0469\n",
      "Epoch 27/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 24138.1055 - mean_squared_error: 24138.1055\n",
      "Epoch 27: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16895.0117 - mean_squared_error: 16895.0117 - val_loss: 60518.8438 - val_mean_squared_error: 60518.8438\n",
      "Epoch 28/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 23736.2305 - mean_squared_error: 23736.2305\n",
      "Epoch 28: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18845.7031 - mean_squared_error: 18845.7031 - val_loss: 59263.1094 - val_mean_squared_error: 59263.1094\n",
      "Epoch 29/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 31558.4922 - mean_squared_error: 31558.4922\n",
      "Epoch 29: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20568.7852 - mean_squared_error: 20568.7852 - val_loss: 57220.3320 - val_mean_squared_error: 57220.3320\n",
      "Epoch 30/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5535.7705 - mean_squared_error: 5535.7705\n",
      "Epoch 30: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20629.5234 - mean_squared_error: 20629.5234 - val_loss: 62108.0156 - val_mean_squared_error: 62108.0156\n",
      "Epoch 31/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 16807.5664 - mean_squared_error: 16807.5664\n",
      "Epoch 31: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19291.8633 - mean_squared_error: 19291.8633 - val_loss: 56017.9375 - val_mean_squared_error: 56017.9375\n",
      "Epoch 32/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 14473.2031 - mean_squared_error: 14473.2031\n",
      "Epoch 32: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24169.9102 - mean_squared_error: 24169.9102 - val_loss: 60066.4883 - val_mean_squared_error: 60066.4883\n",
      "Epoch 33/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17078.7578 - mean_squared_error: 17078.7578\n",
      "Epoch 33: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20659.0547 - mean_squared_error: 20659.0547 - val_loss: 55438.2617 - val_mean_squared_error: 55438.2617\n",
      "Epoch 34/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6737.2744 - mean_squared_error: 6737.2744\n",
      "Epoch 34: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13269.4336 - mean_squared_error: 13269.4336 - val_loss: 54277.5430 - val_mean_squared_error: 54277.5430\n",
      "Epoch 35/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 17638.4824 - mean_squared_error: 17638.4824\n",
      "Epoch 35: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16757.9512 - mean_squared_error: 16757.9512 - val_loss: 59812.5938 - val_mean_squared_error: 59812.5938\n",
      "Epoch 36/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6974.7896 - mean_squared_error: 6974.7896\n",
      "Epoch 36: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22890.4512 - mean_squared_error: 22890.4512 - val_loss: 57031.2070 - val_mean_squared_error: 57031.2070\n",
      "Epoch 37/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 19832.1523 - mean_squared_error: 19832.1523\n",
      "Epoch 37: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15768.5957 - mean_squared_error: 15768.5957 - val_loss: 58074.4258 - val_mean_squared_error: 58074.4258\n",
      "Epoch 38/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 14072.6016 - mean_squared_error: 14072.6016\n",
      "Epoch 38: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22915.2812 - mean_squared_error: 22915.2812 - val_loss: 55936.3008 - val_mean_squared_error: 55936.3008\n",
      "Epoch 39/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 143168.1875 - mean_squared_error: 143168.1875\n",
      "Epoch 39: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28935.3496 - mean_squared_error: 28935.3496 - val_loss: 56004.2031 - val_mean_squared_error: 56004.2031\n",
      "Epoch 40/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21488.9180 - mean_squared_error: 21488.9180\n",
      "Epoch 40: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17362.2598 - mean_squared_error: 17362.2598 - val_loss: 54091.9414 - val_mean_squared_error: 54091.9414\n",
      "Epoch 41/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 32495.3340 - mean_squared_error: 32495.3340\n",
      "Epoch 41: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18760.5703 - mean_squared_error: 18760.5703 - val_loss: 54444.0625 - val_mean_squared_error: 54444.0625\n",
      "Epoch 42/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6674.8389 - mean_squared_error: 6674.8389\n",
      "Epoch 42: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19880.3633 - mean_squared_error: 19880.3633 - val_loss: 55132.9766 - val_mean_squared_error: 55132.9766\n",
      "Epoch 43/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 17095.5039 - mean_squared_error: 17095.5039\n",
      "Epoch 43: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12367.1543 - mean_squared_error: 12367.1543 - val_loss: 55074.7695 - val_mean_squared_error: 55074.7695\n",
      "Epoch 44/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 12757.9473 - mean_squared_error: 12757.9473\n",
      "Epoch 44: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17706.1855 - mean_squared_error: 17706.1855 - val_loss: 55583.1016 - val_mean_squared_error: 55583.1016\n",
      "Epoch 45/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17957.5664 - mean_squared_error: 17957.5664\n",
      "Epoch 45: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17462.3242 - mean_squared_error: 17462.3242 - val_loss: 56984.9961 - val_mean_squared_error: 56984.9961\n",
      "Epoch 46/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 13945.2031 - mean_squared_error: 13945.2031\n",
      "Epoch 46: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14676.6768 - mean_squared_error: 14676.6768 - val_loss: 61101.1289 - val_mean_squared_error: 61101.1289\n",
      "Epoch 47/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 16050.6641 - mean_squared_error: 16050.6641\n",
      "Epoch 47: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21429.4102 - mean_squared_error: 21429.4102 - val_loss: 61968.7695 - val_mean_squared_error: 61968.7695\n",
      "Epoch 48/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 17597.7148 - mean_squared_error: 17597.7148\n",
      "Epoch 48: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22476.8613 - mean_squared_error: 22476.8613 - val_loss: 59636.9453 - val_mean_squared_error: 59636.9453\n",
      "Epoch 49/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 34452.0586 - mean_squared_error: 34452.0586\n",
      "Epoch 49: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14701.8389 - mean_squared_error: 14701.8389 - val_loss: 55217.8398 - val_mean_squared_error: 55217.8398\n",
      "Epoch 50/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8057.0688 - mean_squared_error: 8057.0688\n",
      "Epoch 50: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18152.8906 - mean_squared_error: 18152.8906 - val_loss: 58836.4102 - val_mean_squared_error: 58836.4102\n",
      "Epoch 51/400\n",
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 36542.3125 - mean_squared_error: 36542.3125\n",
      "Epoch 51: val_loss did not improve from 53700.88281\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19537.4570 - mean_squared_error: 19537.4570 - val_loss: 56412.8203 - val_mean_squared_error: 56412.8203\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n"
     ]
    }
   ],
   "source": [
    "# compile and train the model\n",
    "epochs = 400\n",
    "lr = ExponentialDecay(0.01, decay_steps=100000, decay_rate=0.96, staircase=True)\n",
    "stop = EarlyStopping(monitor=\"val_loss\", patience=30, restore_best_weights=True, mode='min', verbose=verbose)\n",
    "best = ModelCheckpoint(\n",
    "    filepath='./model/best_std_weights.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=verbose,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "model_std.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[MeanSquaredError()],\n",
    "    optimizer=Adam(learning_rate=lr, epsilon=1)\n",
    ")\n",
    "plot_model(model_std, show_shapes=True, to_file='./model_std.png')\n",
    "\n",
    "hist_std = model_std.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=epochs,\n",
    "    callbacks=[stop, best],\n",
    "    validation_data=([x_test, y_test])\n",
    ")\n",
    "\n",
    "model_std.save('./model/last_std_weights.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune multi-modal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_XY_data(df:pd.DataFrame):\n",
    "    df_copy = df.copy()\n",
    "    x_imgs = []\n",
    "    y = []\n",
    "    for i, row in df.iterrows():\n",
    "        img_names = row['images_names'].split(',')\n",
    "        for img_name in img_names:\n",
    "            img_path = f'./images/{img_name}'\n",
    "            # print(img_path)\n",
    "            img = load_img(img_path, target_size=img_size)\n",
    "            img = img_to_array(img)\n",
    "            # img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "            x_imgs.append(img)\n",
    "            y.append(row['price'])\n",
    "    Y = pd.DataFrame({'price': y})\n",
    "    x_std = df_copy.drop(['id', 'listing_url', 'images_names', 'images_No', 'price'], axis=1)\n",
    "    x_std = pd.DataFrame(np.repeat(x_std.values, 5, axis=0), columns=x_std.columns)\n",
    "    \n",
    "    return np.array(x_imgs), x_std, Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_imgs(img_list, img_size):\n",
    "#     all_imgs = []\n",
    "#     for img_sublist in img_list:\n",
    "#         imgs_for_one_unit = []\n",
    "#         for img_name in img_sublist:\n",
    "#             img_path = f'./images/{img_name}'\n",
    "#             img = load_img(img_path, img_size)\n",
    "#             img = img_to_array(img)\n",
    "#             imgs_for_one_unit.append(img)\n",
    "#         all_imgs.append(imgs_for_one_unit) \n",
    "        \n",
    "#     all_imgs = np.array(all_imgs)\n",
    "#     print(all_imgs.shape)\n",
    "#     return all_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train imgs len: 5070\n",
      "X_train std shape: (5070, 42)\n",
      "Y_train std shape: (5070, 1)\n",
      "X_test imgs len: 1270\n",
      "X_test std shape: (1270, 42)\n",
      "Y_test std shape: (1270, 1)\n"
     ]
    }
   ],
   "source": [
    "# python code to create the final architecture\n",
    "\n",
    "train_df, test_df, _, _ = train_test_split(data, [0 for _ in range(len(data))], test_size=.2, shuffle=True, random_state=303)\n",
    "# load data (training)\n",
    "x_train_imgs, x_train_std, y_train = split_XY_data(train_df)\n",
    "print(f'X_train imgs len: {len(x_train_imgs)}')\n",
    "print(f'X_train std shape: {x_train_std.shape}')\n",
    "print(f'Y_train std shape: {y_train.shape}')\n",
    "\n",
    "# load data (testing)\n",
    "x_test_imgs, x_test_std, y_test = split_XY_data(test_df)\n",
    "print(f'X_test imgs len: {len(x_test_imgs)}')\n",
    "print(f'X_test std shape: {x_test_std.shape}')\n",
    "print(f'Y_test std shape: {y_test.shape}')\n",
    "\n",
    "# # save loaded images for future use\n",
    "# with open('./model/x_train_imgs.pkl','wb') as train_file, open('./model/x_test_imgs.pkl','wb') as test_file:\n",
    "#     pkl.dump(x_train_imgs, train_file)\n",
    "#     pkl.dump(x_test_imgs, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arr in x_test_imgs:\n",
    "    if arr.shape == (1, 224, 224, 3):\n",
    "        print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build multimodal NN\n",
    "\n",
    "# load fine tuned models\n",
    "# 1) load computer vision model\n",
    "cv_tuned_model_path = './model/best_iv3_weights.keras'\n",
    "cv_tuned_model = keras.models.load_model(cv_tuned_model_path, compile=False)\n",
    "# 2) load structured model\n",
    "std_tuned_model_path = './model/best_std_weights.keras'\n",
    "std_tuned_model = keras.models.load_model(std_tuned_model_path, compile=False)\n",
    "\n",
    "# remove last layer from each model\n",
    "# just to simply identify the layers after concatenation we will add postfix (_cv, _std) for layers\n",
    "# _cv => to layers of computer vision model layers\n",
    "# _std => to layers of structure NN model layers\n",
    "cv_tuned_model_layer = Model(inputs=cv_tuned_model.input, outputs=cv_tuned_model.layers[-2].output)\n",
    "for layer in cv_tuned_model_layer.layers:\n",
    "    layer._name = f'{layer.name}_cv'\n",
    "std_tuned_model_layer = Model(inputs=std_tuned_model.input, outputs=std_tuned_model.layers[-2].output)\n",
    "for layer in std_tuned_model_layer.layers:\n",
    "    layer._name = f'{layer.name}_std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ inception_v3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ avg_pool            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inception_v3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_std     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ avg_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │ input_layer_std[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden_std    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,075</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_hidden[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_hidden_std… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden_final  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,500</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dense_hidden_fin… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ inception_v3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m,      │ \u001b[38;5;34m21,802,784\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ avg_pool            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ inception_v3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_std     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │      \u001b[38;5;34m8,192\u001b[0m │ avg_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)        │      \u001b[38;5;34m1,806\u001b[0m │ input_layer_std[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │    \u001b[38;5;34m131,136\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden_std    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)        │      \u001b[38;5;34m1,075\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_hidden[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_hidden_std… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden_final  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │      \u001b[38;5;34m4,500\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dense_hidden_fin… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,949,544</span> (83.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,949,544\u001b[0m (83.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,911,016</span> (83.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,911,016\u001b[0m (83.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,528</span> (150.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m38,528\u001b[0m (150.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# concate models and add 2 final layer\n",
    "multimodal_structure = concatenate([\n",
    "    cv_tuned_model_layer.output,\n",
    "    std_tuned_model_layer.output\n",
    "])\n",
    "multimodal_structure = Dense(50, activation='relu', name='dense_hidden_final')(multimodal_structure)\n",
    "multimodal_structure = Dense(1, activation='linear')(multimodal_structure)\n",
    "\n",
    "# build model\n",
    "multimodal_model = keras.Model(inputs=[\n",
    "    cv_tuned_model_layer.input[0], \n",
    "    std_tuned_model_layer.input[0]],\n",
    "    outputs=[multimodal_structure]\n",
    ")\n",
    "\n",
    "# model compilation\n",
    "lr = 0.01\n",
    "multimodal_model.compile(\n",
    "    optimizer=Adam(learning_rate=lr, epsilon=1),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[ MeanSquaredError()]\n",
    ")\n",
    "\n",
    "print(multimodal_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# plot model\n",
    "plot_model(\n",
    "    multimodal_model,\n",
    "    dpi=350,\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    to_file=\"multimodal_model.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28s/step - loss: 30794.9785 - mean_squared_error: 30794.9785 \n",
      "Epoch 1: val_loss did not improve from inf\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 29s/step - loss: 30349.7773 - mean_squared_error: 30349.7773 - val_loss: inf - val_mean_squared_error: inf\n",
      "Epoch 2/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 17583.7812 - mean_squared_error: 17583.7812 \n",
      "Epoch 2: val_loss did not improve from inf\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 14s/step - loss: 17589.6523 - mean_squared_error: 17589.6523 - val_loss: inf - val_mean_squared_error: inf\n",
      "Epoch 3/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 16568.1992 - mean_squared_error: 16568.1992\n",
      "Epoch 3: val_loss improved from inf to 50643.82812, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 11s/step - loss: 16611.8184 - mean_squared_error: 16611.8184 - val_loss: 50643.8281 - val_mean_squared_error: 50643.8281\n",
      "Epoch 4/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 15974.9072 - mean_squared_error: 15974.9072\n",
      "Epoch 4: val_loss improved from 50643.82812 to 48850.00000, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 11s/step - loss: 16011.2373 - mean_squared_error: 16011.2373 - val_loss: 48850.0000 - val_mean_squared_error: 48850.0000\n",
      "Epoch 5/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 15698.8887 - mean_squared_error: 15698.8887\n",
      "Epoch 5: val_loss did not improve from 48850.00000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 10s/step - loss: 15712.8223 - mean_squared_error: 15712.8223 - val_loss: 51863.5117 - val_mean_squared_error: 51863.5117\n",
      "Epoch 6/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 16660.8848 - mean_squared_error: 16660.8848\n",
      "Epoch 6: val_loss did not improve from 48850.00000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 10s/step - loss: 16630.5352 - mean_squared_error: 16630.5352 - val_loss: 57960.1445 - val_mean_squared_error: 57960.1445\n",
      "Epoch 7/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 16253.6533 - mean_squared_error: 16253.6533\n",
      "Epoch 7: val_loss did not improve from 48850.00000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 11s/step - loss: 16249.7900 - mean_squared_error: 16249.7900 - val_loss: 49370.7188 - val_mean_squared_error: 49370.7188\n",
      "Epoch 8/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 16274.0254 - mean_squared_error: 16274.0254 \n",
      "Epoch 8: val_loss did not improve from 48850.00000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 10s/step - loss: 16232.4209 - mean_squared_error: 16232.4209 - val_loss: 51661.6953 - val_mean_squared_error: 51661.6953\n",
      "Epoch 9/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 14389.5020 - mean_squared_error: 14389.5020\n",
      "Epoch 9: val_loss improved from 48850.00000 to 48480.11328, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 11s/step - loss: 14417.6885 - mean_squared_error: 14417.6885 - val_loss: 48480.1133 - val_mean_squared_error: 48480.1133\n",
      "Epoch 10/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 11551.4385 - mean_squared_error: 11551.4385\n",
      "Epoch 10: val_loss improved from 48480.11328 to 48241.39844, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 11s/step - loss: 11696.7227 - mean_squared_error: 11696.7227 - val_loss: 48241.3984 - val_mean_squared_error: 48241.3984\n",
      "Epoch 11/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13913.7490 - mean_squared_error: 13913.7490\n",
      "Epoch 11: val_loss did not improve from 48241.39844\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 11s/step - loss: 13961.2803 - mean_squared_error: 13961.2803 - val_loss: 49297.8984 - val_mean_squared_error: 49297.8984\n",
      "Epoch 12/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 16066.4873 - mean_squared_error: 16066.4873\n",
      "Epoch 12: val_loss did not improve from 48241.39844\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 10s/step - loss: 15994.5264 - mean_squared_error: 15994.5264 - val_loss: 53474.0859 - val_mean_squared_error: 53474.0859\n",
      "Epoch 13/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 14015.4307 - mean_squared_error: 14015.4307\n",
      "Epoch 13: val_loss improved from 48241.39844 to 46884.71094, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 11s/step - loss: 14078.2617 - mean_squared_error: 14078.2617 - val_loss: 46884.7109 - val_mean_squared_error: 46884.7109\n",
      "Epoch 14/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 15148.6709 - mean_squared_error: 15148.6709\n",
      "Epoch 14: val_loss did not improve from 46884.71094\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 11s/step - loss: 15135.6592 - mean_squared_error: 15135.6592 - val_loss: 47768.6758 - val_mean_squared_error: 47768.6758\n",
      "Epoch 15/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13130.8271 - mean_squared_error: 13130.8271\n",
      "Epoch 15: val_loss did not improve from 46884.71094\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 10s/step - loss: 13183.4238 - mean_squared_error: 13183.4238 - val_loss: 47912.6562 - val_mean_squared_error: 47912.6562\n",
      "Epoch 16/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13854.3691 - mean_squared_error: 13854.3691\n",
      "Epoch 16: val_loss did not improve from 46884.71094\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 11s/step - loss: 13875.8818 - mean_squared_error: 13875.8818 - val_loss: 47838.8203 - val_mean_squared_error: 47838.8203\n",
      "Epoch 17/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 12462.8232 - mean_squared_error: 12462.8232\n",
      "Epoch 17: val_loss did not improve from 46884.71094\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 11s/step - loss: 12566.2471 - mean_squared_error: 12566.2471 - val_loss: 49398.0938 - val_mean_squared_error: 49398.0938\n",
      "Epoch 18/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13282.6309 - mean_squared_error: 13282.6309\n",
      "Epoch 18: val_loss improved from 46884.71094 to 45157.89844, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 11s/step - loss: 13311.6611 - mean_squared_error: 13311.6611 - val_loss: 45157.8984 - val_mean_squared_error: 45157.8984\n",
      "Epoch 19/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13992.3877 - mean_squared_error: 13992.3877\n",
      "Epoch 19: val_loss did not improve from 45157.89844\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 11s/step - loss: 13991.5439 - mean_squared_error: 13991.5439 - val_loss: 47495.2266 - val_mean_squared_error: 47495.2266\n",
      "Epoch 20/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13532.2383 - mean_squared_error: 13532.2383\n",
      "Epoch 20: val_loss did not improve from 45157.89844\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 10s/step - loss: 13551.7666 - mean_squared_error: 13551.7666 - val_loss: 46625.4688 - val_mean_squared_error: 46625.4688\n",
      "Epoch 21/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 16547.5254 - mean_squared_error: 16547.5254\n",
      "Epoch 21: val_loss did not improve from 45157.89844\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 11s/step - loss: 16400.0801 - mean_squared_error: 16400.0801 - val_loss: 48062.1328 - val_mean_squared_error: 48062.1328\n",
      "Epoch 22/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 15699.9629 - mean_squared_error: 15699.9629\n",
      "Epoch 22: val_loss did not improve from 45157.89844\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 11s/step - loss: 15579.6211 - mean_squared_error: 15579.6211 - val_loss: 45878.2578 - val_mean_squared_error: 45878.2578\n",
      "Epoch 23/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13339.1133 - mean_squared_error: 13339.1133\n",
      "Epoch 23: val_loss improved from 45157.89844 to 44365.24219, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 11s/step - loss: 13349.2939 - mean_squared_error: 13349.2939 - val_loss: 44365.2422 - val_mean_squared_error: 44365.2422\n",
      "Epoch 24/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 17374.3223 - mean_squared_error: 17374.3223\n",
      "Epoch 24: val_loss did not improve from 44365.24219\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 10s/step - loss: 17163.1504 - mean_squared_error: 17163.1504 - val_loss: 47472.8359 - val_mean_squared_error: 47472.8359\n",
      "Epoch 25/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 11547.0684 - mean_squared_error: 11547.0684\n",
      "Epoch 25: val_loss did not improve from 44365.24219\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 11s/step - loss: 11626.7217 - mean_squared_error: 11626.7217 - val_loss: 56063.9453 - val_mean_squared_error: 56063.9453\n",
      "Epoch 26/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 14236.9150 - mean_squared_error: 14236.9150\n",
      "Epoch 26: val_loss improved from 44365.24219 to 42738.40625, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 11s/step - loss: 14273.3984 - mean_squared_error: 14273.3984 - val_loss: 42738.4062 - val_mean_squared_error: 42738.4062\n",
      "Epoch 27/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 12931.9316 - mean_squared_error: 12931.9316 \n",
      "Epoch 27: val_loss did not improve from 42738.40625\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 10s/step - loss: 12956.1465 - mean_squared_error: 12956.1465 - val_loss: 51702.3945 - val_mean_squared_error: 51702.3945\n",
      "Epoch 28/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 12999.3320 - mean_squared_error: 12999.3320 \n",
      "Epoch 28: val_loss improved from 42738.40625 to 41530.16406, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 11s/step - loss: 13035.4365 - mean_squared_error: 13035.4365 - val_loss: 41530.1641 - val_mean_squared_error: 41530.1641\n",
      "Epoch 29/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13415.2559 - mean_squared_error: 13415.2559 \n",
      "Epoch 29: val_loss did not improve from 41530.16406\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 11s/step - loss: 13473.8467 - mean_squared_error: 13473.8467 - val_loss: 49022.0664 - val_mean_squared_error: 49022.0664\n",
      "Epoch 30/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 14734.1992 - mean_squared_error: 14734.1992 \n",
      "Epoch 30: val_loss did not improve from 41530.16406\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 11s/step - loss: 14692.7969 - mean_squared_error: 14692.7969 - val_loss: 43391.3047 - val_mean_squared_error: 43391.3047\n",
      "Epoch 31/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13041.1738 - mean_squared_error: 13041.1738\n",
      "Epoch 31: val_loss did not improve from 41530.16406\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 11s/step - loss: 13015.0781 - mean_squared_error: 13015.0781 - val_loss: 44702.1211 - val_mean_squared_error: 44702.1211\n",
      "Epoch 32/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 10377.8330 - mean_squared_error: 10377.8330\n",
      "Epoch 32: val_loss improved from 41530.16406 to 34694.21094, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 11s/step - loss: 10456.1152 - mean_squared_error: 10456.1152 - val_loss: 34694.2109 - val_mean_squared_error: 34694.2109\n",
      "Epoch 33/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 15025.9531 - mean_squared_error: 15025.9531\n",
      "Epoch 33: val_loss did not improve from 34694.21094\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 10s/step - loss: 14942.6738 - mean_squared_error: 14942.6738 - val_loss: 44160.5469 - val_mean_squared_error: 44160.5469\n",
      "Epoch 34/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 11401.4551 - mean_squared_error: 11401.4551 \n",
      "Epoch 34: val_loss improved from 34694.21094 to 34143.69531, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 11s/step - loss: 11464.2500 - mean_squared_error: 11464.2500 - val_loss: 34143.6953 - val_mean_squared_error: 34143.6953\n",
      "Epoch 35/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 12986.2998 - mean_squared_error: 12986.2998 \n",
      "Epoch 35: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 10s/step - loss: 12997.7129 - mean_squared_error: 12997.7129 - val_loss: 44995.9375 - val_mean_squared_error: 44995.9375\n",
      "Epoch 36/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 14723.0254 - mean_squared_error: 14723.0254\n",
      "Epoch 36: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 10s/step - loss: 14775.0527 - mean_squared_error: 14775.0527 - val_loss: 63968.5117 - val_mean_squared_error: 63968.5117\n",
      "Epoch 37/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 16734.1113 - mean_squared_error: 16734.1113\n",
      "Epoch 37: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 11s/step - loss: 16624.0645 - mean_squared_error: 16624.0645 - val_loss: 47542.7930 - val_mean_squared_error: 47542.7930\n",
      "Epoch 38/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 15128.7031 - mean_squared_error: 15128.7031\n",
      "Epoch 38: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 10s/step - loss: 15008.6289 - mean_squared_error: 15008.6289 - val_loss: 41565.8594 - val_mean_squared_error: 41565.8594\n",
      "Epoch 39/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13237.8203 - mean_squared_error: 13237.8203\n",
      "Epoch 39: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 10s/step - loss: 13296.1348 - mean_squared_error: 13296.1348 - val_loss: 53115.1680 - val_mean_squared_error: 53115.1680\n",
      "Epoch 40/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13351.1895 - mean_squared_error: 13351.1895\n",
      "Epoch 40: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 10s/step - loss: 13354.8154 - mean_squared_error: 13354.8154 - val_loss: 46189.0391 - val_mean_squared_error: 46189.0391\n",
      "Epoch 41/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 11730.3232 - mean_squared_error: 11730.3232\n",
      "Epoch 41: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 10s/step - loss: 11799.4277 - mean_squared_error: 11799.4277 - val_loss: 38266.8242 - val_mean_squared_error: 38266.8242\n",
      "Epoch 42/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13478.3984 - mean_squared_error: 13478.3984\n",
      "Epoch 42: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 11s/step - loss: 13485.3740 - mean_squared_error: 13485.3740 - val_loss: 42178.1914 - val_mean_squared_error: 42178.1914\n",
      "Epoch 43/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 11515.0449 - mean_squared_error: 11515.0449\n",
      "Epoch 43: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 10s/step - loss: 11601.3770 - mean_squared_error: 11601.3770 - val_loss: 57023.4258 - val_mean_squared_error: 57023.4258\n",
      "Epoch 44/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 15731.0645 - mean_squared_error: 15731.0645\n",
      "Epoch 44: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 10s/step - loss: 15679.7422 - mean_squared_error: 15679.7422 - val_loss: 44637.6211 - val_mean_squared_error: 44637.6211\n",
      "Epoch 45/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 10764.6650 - mean_squared_error: 10764.6650 \n",
      "Epoch 45: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 10s/step - loss: 10846.9502 - mean_squared_error: 10846.9502 - val_loss: 37701.7578 - val_mean_squared_error: 37701.7578\n",
      "Epoch 46/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 9800.3584 - mean_squared_error: 9800.3584\n",
      "Epoch 46: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 11s/step - loss: 9851.6904 - mean_squared_error: 9851.6904 - val_loss: 35803.7812 - val_mean_squared_error: 35803.7812\n",
      "Epoch 47/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 9774.2090 - mean_squared_error: 9774.2090\n",
      "Epoch 47: val_loss did not improve from 34143.69531\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 11s/step - loss: 9800.5908 - mean_squared_error: 9800.5908 - val_loss: 38279.7188 - val_mean_squared_error: 38279.7188\n",
      "Epoch 48/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 9282.6445 - mean_squared_error: 9282.6445\n",
      "Epoch 48: val_loss improved from 34143.69531 to 32727.49023, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 11s/step - loss: 9321.0469 - mean_squared_error: 9321.0469 - val_loss: 32727.4902 - val_mean_squared_error: 32727.4902\n",
      "Epoch 49/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 11260.2002 - mean_squared_error: 11260.2002 \n",
      "Epoch 49: val_loss improved from 32727.49023 to 31580.23438, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 11s/step - loss: 11251.8086 - mean_squared_error: 11251.8086 - val_loss: 31580.2344 - val_mean_squared_error: 31580.2344\n",
      "Epoch 50/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 9685.2793 - mean_squared_error: 9685.2793\n",
      "Epoch 50: val_loss improved from 31580.23438 to 29186.06250, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 11s/step - loss: 9712.6045 - mean_squared_error: 9712.6045 - val_loss: 29186.0625 - val_mean_squared_error: 29186.0625\n",
      "Epoch 51/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 10482.8232 - mean_squared_error: 10482.8232\n",
      "Epoch 51: val_loss did not improve from 29186.06250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 11s/step - loss: 10535.8262 - mean_squared_error: 10535.8262 - val_loss: 29424.6758 - val_mean_squared_error: 29424.6758\n",
      "Epoch 52/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - loss: 11265.9697 - mean_squared_error: 11265.9697 \n",
      "Epoch 52: val_loss improved from 29186.06250 to 27645.04688, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 11s/step - loss: 11281.7705 - mean_squared_error: 11281.7705 - val_loss: 27645.0469 - val_mean_squared_error: 27645.0469\n",
      "Epoch 53/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13863.6240 - mean_squared_error: 13863.6240\n",
      "Epoch 53: val_loss improved from 27645.04688 to 23983.13281, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 11s/step - loss: 13816.2822 - mean_squared_error: 13816.2822 - val_loss: 23983.1328 - val_mean_squared_error: 23983.1328\n",
      "Epoch 54/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 9433.0332 - mean_squared_error: 9433.0332\n",
      "Epoch 54: val_loss improved from 23983.13281 to 23582.01953, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 11s/step - loss: 9471.4883 - mean_squared_error: 9471.4883 - val_loss: 23582.0195 - val_mean_squared_error: 23582.0195\n",
      "Epoch 55/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 9169.5205 - mean_squared_error: 9169.5205\n",
      "Epoch 55: val_loss did not improve from 23582.01953\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 10s/step - loss: 9239.4814 - mean_squared_error: 9239.4814 - val_loss: 39066.5039 - val_mean_squared_error: 39066.5039\n",
      "Epoch 56/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 12210.5518 - mean_squared_error: 12210.5518\n",
      "Epoch 56: val_loss did not improve from 23582.01953\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 10s/step - loss: 12211.1055 - mean_squared_error: 12211.1055 - val_loss: 31622.7773 - val_mean_squared_error: 31622.7773\n",
      "Epoch 57/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 13117.6416 - mean_squared_error: 13117.6416\n",
      "Epoch 57: val_loss did not improve from 23582.01953\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 10s/step - loss: 13051.7529 - mean_squared_error: 13051.7529 - val_loss: 25820.1152 - val_mean_squared_error: 25820.1152\n",
      "Epoch 58/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 8473.5713 - mean_squared_error: 8473.5713\n",
      "Epoch 58: val_loss improved from 23582.01953 to 16533.75586, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 11s/step - loss: 8524.6582 - mean_squared_error: 8524.6582 - val_loss: 16533.7559 - val_mean_squared_error: 16533.7559\n",
      "Epoch 59/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 9035.8965 - mean_squared_error: 9035.8965\n",
      "Epoch 59: val_loss improved from 16533.75586 to 14945.52832, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 11s/step - loss: 9007.0156 - mean_squared_error: 9007.0156 - val_loss: 14945.5283 - val_mean_squared_error: 14945.5283\n",
      "Epoch 60/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7997.0356 - mean_squared_error: 7997.0356\n",
      "Epoch 60: val_loss did not improve from 14945.52832\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 10s/step - loss: 7985.7334 - mean_squared_error: 7985.7334 - val_loss: 20597.0430 - val_mean_squared_error: 20597.0430\n",
      "Epoch 61/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 8429.5615 - mean_squared_error: 8429.5615\n",
      "Epoch 61: val_loss did not improve from 14945.52832\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 11s/step - loss: 8399.0645 - mean_squared_error: 8399.0645 - val_loss: 16234.5879 - val_mean_squared_error: 16234.5879\n",
      "Epoch 62/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7593.1958 - mean_squared_error: 7593.1958\n",
      "Epoch 62: val_loss did not improve from 14945.52832\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 11s/step - loss: 7623.2905 - mean_squared_error: 7623.2905 - val_loss: 17513.3789 - val_mean_squared_error: 17513.3789\n",
      "Epoch 63/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7830.1167 - mean_squared_error: 7830.1167\n",
      "Epoch 63: val_loss did not improve from 14945.52832\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 10s/step - loss: 7838.4053 - mean_squared_error: 7838.4053 - val_loss: 20991.1348 - val_mean_squared_error: 20991.1348\n",
      "Epoch 64/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7588.6021 - mean_squared_error: 7588.6021\n",
      "Epoch 64: val_loss improved from 14945.52832 to 11679.98047, saving model to ./model/best_multimodal_weights.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 11s/step - loss: 7603.3315 - mean_squared_error: 7603.3315 - val_loss: 11679.9805 - val_mean_squared_error: 11679.9805\n",
      "Epoch 65/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 8177.7280 - mean_squared_error: 8177.7280 \n",
      "Epoch 65: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 19s/step - loss: 8195.1777 - mean_squared_error: 8195.1777 - val_loss: 14993.2188 - val_mean_squared_error: 14993.2188\n",
      "Epoch 66/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 8605.0986 - mean_squared_error: 8605.0986\n",
      "Epoch 66: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 11s/step - loss: 8547.9248 - mean_squared_error: 8547.9248 - val_loss: 14850.9473 - val_mean_squared_error: 14850.9473\n",
      "Epoch 67/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 7512.1309 - mean_squared_error: 7512.1309\n",
      "Epoch 67: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 12s/step - loss: 7502.0801 - mean_squared_error: 7502.0801 - val_loss: 16580.1680 - val_mean_squared_error: 16580.1680\n",
      "Epoch 68/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 7087.4341 - mean_squared_error: 7087.4341 \n",
      "Epoch 68: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 18s/step - loss: 7089.7974 - mean_squared_error: 7089.7974 - val_loss: 18807.7852 - val_mean_squared_error: 18807.7852\n",
      "Epoch 69/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19s/step - loss: 8140.5039 - mean_squared_error: 8140.5039 \n",
      "Epoch 69: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 21s/step - loss: 8131.2432 - mean_squared_error: 8131.2432 - val_loss: 19134.6270 - val_mean_squared_error: 19134.6270\n",
      "Epoch 70/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19s/step - loss: 9113.2188 - mean_squared_error: 9113.2188 \n",
      "Epoch 70: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 21s/step - loss: 9106.5508 - mean_squared_error: 9106.5508 - val_loss: 23730.4043 - val_mean_squared_error: 23730.4043\n",
      "Epoch 71/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19s/step - loss: 8043.5645 - mean_squared_error: 8043.5645 \n",
      "Epoch 71: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 21s/step - loss: 8039.2939 - mean_squared_error: 8039.2939 - val_loss: 39092.6719 - val_mean_squared_error: 39092.6719\n",
      "Epoch 72/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - loss: 8101.2227 - mean_squared_error: 8101.2227 \n",
      "Epoch 72: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 15s/step - loss: 8129.6138 - mean_squared_error: 8129.6138 - val_loss: 14515.0000 - val_mean_squared_error: 14515.0000\n",
      "Epoch 73/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 6883.4360 - mean_squared_error: 6883.4360\n",
      "Epoch 73: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 11s/step - loss: 6878.3955 - mean_squared_error: 6878.3955 - val_loss: 14965.6270 - val_mean_squared_error: 14965.6270\n",
      "Epoch 74/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 6834.7651 - mean_squared_error: 6834.7651\n",
      "Epoch 74: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 11s/step - loss: 6847.9185 - mean_squared_error: 6847.9185 - val_loss: 17434.5195 - val_mean_squared_error: 17434.5195\n",
      "Epoch 75/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - loss: 5908.4531 - mean_squared_error: 5908.4531 \n",
      "Epoch 75: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 13s/step - loss: 5932.9097 - mean_squared_error: 5932.9097 - val_loss: 25566.4805 - val_mean_squared_error: 25566.4805\n",
      "Epoch 76/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 6446.6582 - mean_squared_error: 6446.6582\n",
      "Epoch 76: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 10s/step - loss: 6469.8198 - mean_squared_error: 6469.8198 - val_loss: 23870.9922 - val_mean_squared_error: 23870.9922\n",
      "Epoch 77/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - loss: 8754.8574 - mean_squared_error: 8754.8574 \n",
      "Epoch 77: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 14s/step - loss: 8753.3535 - mean_squared_error: 8753.3535 - val_loss: 52669.1172 - val_mean_squared_error: 52669.1172\n",
      "Epoch 78/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 10151.3945 - mean_squared_error: 10151.3945\n",
      "Epoch 78: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 11s/step - loss: 10146.6445 - mean_squared_error: 10146.6445 - val_loss: 21018.7402 - val_mean_squared_error: 21018.7402\n",
      "Epoch 79/400\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 8579.7930 - mean_squared_error: 8579.7930\n",
      "Epoch 79: val_loss did not improve from 11679.98047\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 11s/step - loss: 8563.5068 - mean_squared_error: 8563.5068 - val_loss: 21869.9199 - val_mean_squared_error: 21869.9199\n",
      "Epoch 79: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, mode='min', verbose=verbose)\n",
    "best = ModelCheckpoint(\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True, \n",
    "    save_weights_only=False, \n",
    "    filepath='./model/best_multimodal_weights.keras'\n",
    ")\n",
    "\n",
    "hist_multimodal = multimodal_model.fit(\n",
    "    [x_train_imgs, x_train_std],\n",
    "    y_train,                   \n",
    "    epochs=epochs,\n",
    "    batch_size = 256,\n",
    "    validation_data=([x_test_imgs, x_test_std], y_test),\n",
    "    callbacks=[stop, best]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
